{"docstore/metadata": {"efec9943-e9f3-4fb3-97d5-3d3c43b186da": {"doc_hash": "af56a585e7add11430558ee1d753b38ad5818778967612bb66c0a83fe319379c"}, "0d2a1c0e-3ec6-4148-9249-476234bbd548": {"doc_hash": "2e43a7a21de015014fc470d2933fa94c0393eeb8c80d6ccd01eff29b512c219c"}, "5fc9bb01-c198-4beb-971e-c4e38fdb105e": {"doc_hash": "c9a07eff8d1acacf2e1c63debde41708f7ac9a6b8eda1bed8ec58bf70cb593ec"}, "d2cbbbfd-5a41-4cb2-b0e6-9a7626976fd4": {"doc_hash": "b33821ff27b344d7d77bb3f2122e059fbdae6674953e7efe6945507e44ef62f9"}, "1c0d1f46-032b-400c-b0a4-8544a4aa3565": {"doc_hash": "71ad8edb342bb211803d1c444cdfca70cfdf52d357f479f592f896c1cea07c97"}, "94e58f55-8e6c-4dfd-8d88-442641245808": {"doc_hash": "bb22c2433e3cd819a110f3f2f7fb10abbaaeb2df16d7ab39eaec7503c9581214"}, "b38ccd80-2127-4124-a3ce-6c8c8880341d": {"doc_hash": "789a295f094713c6a323eb93b403be93fa23f2fe1011006a0a4ac70ad2542b3b"}, "331cc524-546f-4571-9301-55cf3aa2e4ce": {"doc_hash": "3ec2543f2483e29a1de3534b46e7213a89be89cbcdf23087e7de50b023b11117"}, "3c6c1455-49b3-42c5-a734-e61f987987e0": {"doc_hash": "002dd66e7cd0684e57d2c71fb9370832a102dbcd1645d9b75e0733a19a55cff2"}, "2b4cba27-36e3-4c6a-b199-e713e009eb0f": {"doc_hash": "8f859679fe4c27480996f3c39818da9de19e9bd18c08ea7c7fb2ea70000b3424"}, "0c59fad0-d09c-4591-907e-9f2a91c4251c": {"doc_hash": "2c096d6103e70b11be97e97c9cb06a5322e927f244161e124fac54ef34bc1791"}, "425983d7-9f85-4957-aac1-a11a5a0fd830": {"doc_hash": "085c58a4f9730281d9abed3144138adcb644b8991f96003eec4de21abc9504f7"}, "78386276-c367-40c7-a874-db9deabfbbd0": {"doc_hash": "05d7a10f38b7183ec3745bdf9f9fe0f8e0a258fe66bb95ae5bd2d77246aabb17"}, "229d3b60-4586-4716-8420-71fc18ed5c84": {"doc_hash": "794bb906e68f6eb42a8b57774f0e7a3b7141fe287ff665b1ed7a31a6a1129dcc"}, "2984c14c-c6a7-47b2-83be-f7e580e0a7f3": {"doc_hash": "9f373b83b66feb2df52a738178b39844b330679cf348eac8c9c5d6190143f096"}, "fe369b22-9247-495d-9d97-42f5c5dad7cd": {"doc_hash": "35a6b7858e2d7ec55f606874c1f613bb3a0fe603f9b7c5e3308f56c8d335c2b4"}, "1373c2ef-1694-4c60-a74c-c22c9e0cd57d": {"doc_hash": "3c86c37bfa3149d198e0a5d12d7abd0844543aaa9c5c06c11a0feea1fbad4535"}, "d69b4e5d-dc4f-4268-ac2f-a56814a0147a": {"doc_hash": "747eea3e4d1f3b85dc436d31907677c33bc69acc19a8eb2f11bead473d77ac7f"}, "38a9c9ff-b438-4de9-91c7-d85959b0a7f9": {"doc_hash": "6b1c54f53a78de218c7fbb702e2a315a372acbdf9e9d95ad060e0c6edaf582f6"}, "fddb99a6-073e-4759-ae24-517327a18cb6": {"doc_hash": "39f81223a6a01687118801ce5d6ade49e8b1f598b5492a3eaa8e4f5ae108d57a"}, "8b3f3a1b-7338-4a3e-9122-584c85d5e6b4": {"doc_hash": "0a186f929482349b741cc94d0a64c59b18eb2d85d2f5e070632ecabd9e05af2f"}, "444001b9-6899-4de3-be0c-867d14a7dcc8": {"doc_hash": "80b7f5d7db0680422c76078bef9d94c06032a21ea76b05f751c3e5f6ba166c81"}, "1d55e6a8-85da-4ee3-8835-cb6237151041": {"doc_hash": "e4ef028d8e2167dcfec423961255d31097da7445586d0e929063efce9eb27ab9"}, "685b87a4-a63a-4f4a-afce-8d54bd12428b": {"doc_hash": "016dd8b53cf59693edcc1fc1a55824ac234e1822934ac07ef9d46982fe51b925"}, "8ad38b29-a0b4-4396-883f-cd7dbb4ff242": {"doc_hash": "a97ef4b13ac6e1270924874d5c46f8cc631f34c904097ac4b9f366ff2197e979"}, "4581b228-3f4f-469d-b99a-9ae855107933": {"doc_hash": "219703d31430f1a9973f6c7c26a12aa797f5958f4017989dabe05b30f3c9c164"}, "3cc7b2c6-65c8-4f24-b05e-161ad615bc76": {"doc_hash": "15be8ac9c19ffab1278dfba57e21edc1788a02b9e5ebe7c58d01df4093faa02d"}, "f2a52cd5-3355-4e8e-8b4b-0c00511168bd": {"doc_hash": "c086f26dacc50f9336a88878944e23c3af6cb9ab6868891d5183a39bd2ae1988"}, "cd9a62c9-a498-4b1e-90bb-a09fe694d186": {"doc_hash": "d257adc678f4d1fc170f95def19f18fc118e93631544a7a3473dd7ff69234d81"}, "bd233b25-58e1-4100-957b-2aceb6d31439": {"doc_hash": "5dc6dcb3d9f38847c4e2f27e4f80de019aee85a80f33074e28ae7ee461368a92"}, "3385ad0b-4bf0-4930-809b-4d5d52134971": {"doc_hash": "958592970d1384e5af1246804ebfa6276fda8a1868d34f61203ea328a6d2fdc4"}, "23508db5-40c0-4fec-9072-f424dedbf83d": {"doc_hash": "0ce41f743359de59a6465d4e13e7e04ae958962eadffa7430ae8c4db8b2dccae"}, "1e570c30-dd39-4ce0-b593-b2370846a169": {"doc_hash": "f3c9a57b15b08a0086fc05b066b7516917d5c8c114bbb7ab2571e9bc974990b1"}, "7fe31f27-ffe0-4454-ab01-ee87fc3a690a": {"doc_hash": "b9993422268fc6f621dd405d6884bf8232491c314eb13931aaa96fe3e79992b9"}, "9920c8c9-c70d-4cb5-a982-da0849dd3518": {"doc_hash": "766df0585e4543b3482334f78f453331f057e3771a7a259863a27c0c9fccb9ab"}, "ebb7bd7c-7c8b-400e-aa05-9c5621782ecf": {"doc_hash": "b03988abc5ed24b15b2be62262d8e97c9656b1ecf9c3aca7aec41b95a8b01bcf"}, "d6adebef-c6eb-43e5-a41b-705aa73f039f": {"doc_hash": "9eb769c013b6f4a7e31256ba04445bd5f316a3199b0982b5bdf7bedcb66d9c16"}, "0d24d8be-692c-4f63-b249-0e5ad54d4d36": {"doc_hash": "9b2b54fb88b8bc62f1f9bd9e6e35d72260209be022092e46099fee6e9e7f3006"}, "b0f4050a-7ffb-4c63-a758-ff58ebbf9917": {"doc_hash": "4a876c4f6e5f9f0bc7d8f2ccda1fc63e946189e7960fb9b486c4ae0c07246eb1"}, "4962a225-fcfa-49d3-9057-1971b9c80a8e": {"doc_hash": "38fa514534f2f4d341017f37b0bce1eed487d19ab43db463c1dc44344841d897"}, "b058a491-3b2f-455f-bcca-eb8c4fdec613": {"doc_hash": "5fa2dc72b2b9593066394be7e4f73e959d6a0c4edf697906660af7672a68c43f"}, "6d4f2826-f04e-4ab3-9bb8-ffe09dee2cf1": {"doc_hash": "a2e2066530835620ed4137c3fc4ac83e795354e5c6ab4a02e7fd54816f0c72e6"}, "83129db1-45fd-4021-9b44-97fefac46450": {"doc_hash": "25ff09b0e23d47cafc718f75ac374ad66284b92747cca17c97b54759f9ea5fe1"}, "10f4f69a-6a9b-4bff-8f0a-e1085758fe55": {"doc_hash": "b169b298d34447df8c420e076dd1e99574eb7a8ce625a761ec9164aaab0e288c"}, "08385f70-454d-45b0-9171-af64e87c6951": {"doc_hash": "108b7a9cfe815f2d7e73e3dfd6ef519e27c4c5335a1610d481f5379c011e9426"}, "ac8aebe1-1c14-4e3b-9b69-1c58c5ca2a83": {"doc_hash": "51877aac883219d7fe86eb4451774bae868c75f85625eaf784b136579697f9fd"}, "7ab48f9b-296b-40e4-a82f-6116166d21d1": {"doc_hash": "67164d6c1994201e98146acc88e152dc3249daeb449027022b5f0e00bb09084a"}, "6c7b18c9-3faf-4afd-95a5-e8f007f574c5": {"doc_hash": "f9e6388651bd0c5522b473dcd6db0885be2329904fdd1d915fb4724e6b676667"}, "b7182f09-b4e1-4120-ad60-21f3c5477de7": {"doc_hash": "432ffcd2bcfc24c7c81fb8e77390358099ca0ae354ba0fb814ac8399dd2fe945"}, "3506ae53-2e19-4e96-9a91-9b800526440a": {"doc_hash": "84e5ad42f2c8bbefeaae2c3176c3502b24b6b5faac93885b4d93f1b7c09b798f"}, "f7c7ceb4-411c-4497-a477-a69ae4300b59": {"doc_hash": "b44f8aedbbab26dce5fc6d6ace22924d63a98cbe8d124571e454ccb8f408905e"}, "854373b4-2ed9-4bfd-aa04-29a6455c93d7": {"doc_hash": "9ae55a6cedd253347c90246983970890837e94c0abeadceb4d529c932e52e053"}, "38a891d3-a6f0-4b8b-a58a-715ecb821927": {"doc_hash": "ba6824e7716b9e49ce3d752844bab8c35eb5b4ae68ad3dee21e32406c63226c8"}, "fc3b4a27-eabb-4912-96bf-322c5d433c6c": {"doc_hash": "60911afebd4e8be9bb7f4dc1f43f50f02819f0467f4cb4409c8bebc3d5268c41"}, "aab364b8-44ff-4650-8dcb-9d5641d7b68d": {"doc_hash": "b6c190d2762d3d92e1fc25cd07cf4ede566abe964c8519544ce8ace3b628a2b4"}, "5d78f080-10bc-4458-8f5c-850f04ffdfeb": {"doc_hash": "6c8083b2660fc8d4d32b0a4bd6439a7de02498b2ca8e0b684f9ea40fcdeeb6c9"}, "640347d5-3738-46c8-b4a4-f5df9d48f810": {"doc_hash": "8749bdc6bbe31726957816e2a7bb15919a73ceb661c9f658bd6d2ad08d0d56f6"}, "5c39a593-b837-494b-8116-4390d85cf281": {"doc_hash": "4d37c7875ec4af5b935a4833a7fb511b3c2b385c06dd6d75d8c8ad451d883c02"}, "f1149b95-a761-4a10-88ca-3c521506e885": {"doc_hash": "c279d392f2c0cafb2bda579f28c306b37aaa439367366977e9cf8915efe9dd8a"}, "34444987-dd7b-43f2-bf76-fb289ffae1fa": {"doc_hash": "66badfd76d983b7f15c6c9d99e4423e11413a0c8479f521e3335a0684f6b5e25"}, "3ba133f4-e84f-4b65-97c5-2debb3b0df0c": {"doc_hash": "2c317e51841f2cac230e1f4fb2712e13eec029607d379fccf725b258c43df461"}, "e9841f25-8514-4d6d-805e-81e6731f0ec9": {"doc_hash": "e8c673550fb1f1eb8ab786965d9709b2c622cf7e6b6e6877bb18815dc58e4eab"}, "5d140a99-34a8-48d2-9a3b-2d6aa6d2f5c2": {"doc_hash": "79a319149b627288314a2b0c97cf3d67217a5b4f91ae77c697b19f2f69431b53"}, "91a6c7f2-45fe-418d-86cc-f274852408c5": {"doc_hash": "a5f9748a7ea55f1f597e8bd08e3fe6f417518d4e1923fde3575abb95ce8a2c27"}, "e9483f45-7cae-49f1-b462-3a24c00c7f0c": {"doc_hash": "bb545bc76bd14510885abb9712c0004ed7fa9b50e09b7053a039db5857439fe2"}, "a586736c-bddb-4322-b257-0cc45713bbb5": {"doc_hash": "0bf150175fb4e93529877a2cd3b41148b007213e6969eef7e226b7553237ea3b"}, "ddb354c3-0212-4263-bbc2-05125ec89a6f": {"doc_hash": "2e2a2a9dd948df4b68d5e0e6cc2e045cb78f3f960bdc3af3b1d5312f7eea3aa9"}, "01c0c0d1-b8be-4b29-b3a3-4bc609f73819": {"doc_hash": "fd4501ca5bf18b4ad1921b2f65ff187edcec7aa37733a942b9b10a167464eee5"}, "44071d89-212c-4714-953e-950cae500e7d": {"doc_hash": "a079462cb1a0cebb7d05f9bfe45f0f8bcc666f4217f36303f41b53eb0426f1e8"}, "90c9fb37-6f25-4b81-bec7-213f75767395": {"doc_hash": "05ed150ae150899149fae9aa6f493fb6eebda4d03e24dda6e31bd6eea3455e05"}, "0323df1d-53c9-4b1f-af91-39b8174dcf4e": {"doc_hash": "0ed3a154e1944e6d737d71a38ce412fb39ec920775aeb228c407bac3c4c37754"}, "eb6f6260-d5a8-400c-9f7b-41e2a083b1a3": {"doc_hash": "ead9b0ccbac26fdaf6d44654b15d99663b2fbbd64f64fe552d6e0204890044b9"}, "2b3b1e49-618a-4885-992d-ae06c1fb7a4e": {"doc_hash": "7645ed8a1799d653bfccd8071d4b334cea2b5982902e28bd491c261aa4aa99e8"}, "23643c82-3c82-4846-85d3-dbbb6f504561": {"doc_hash": "d07d961758b90f92eb4448d0219ece8a9fccd548e25d3f359eb7ba6360d739a4"}, "b9793ff4-59e4-4749-af15-12c52ccd9f84": {"doc_hash": "ea111962282b0c5c3b400e6157304fdb0d12315b8db3d7b01c8edeaf08059a90"}, "c9c564fe-88e9-4d48-954d-e720d7c8f7b2": {"doc_hash": "c5e092377621eed0f255342cae514ea24877d3dbb0da758b886e260edd545596"}, "2938da21-4392-4b11-abc5-7791595fbb18": {"doc_hash": "763e5810f5bf37d9999d5dcdb35fc0bd10048e47bff8c616f3a1c82499f7449a"}, "9823604f-a141-45bc-b693-724630fc08e5": {"doc_hash": "f781582f5aa49ce2eefc25a08a261258a6aae142bba9179d92fc395ee6dc93dc"}, "631941fd-6d25-4ec5-9372-0edbccc99634": {"doc_hash": "28ac4acbcac2e25affecc443a3033e3aa99a903ce034e05610736efb8b764e91"}, "eda414b3-c1f2-4eea-9328-5e8b9bf277eb": {"doc_hash": "d7719f5191b1db72c480f6f5ff26dbea3ce6f705384a4de64f9970fb06c49ae4"}, "dbe35e52-c484-450b-9e00-41860c60b07d": {"doc_hash": "0b94b7a3a602657d73ffd3730fbe53cdcce51ece285ac1713d0743810700ccd5"}, "6a265fd7-4c71-4257-aca0-4466706f024c": {"doc_hash": "b3a31c073482b4e8bb2c32164fc8c3874036582e8c718166fd9f0ba5383b5741"}, "4ad6f52f-ff2a-4ae3-af91-7662b4322833": {"doc_hash": "12029ec7c2739a049ab39fae722f2e1b9879ebd3186a523bd1935131cfd317a4"}, "6dc1a8e3-e993-4ed0-934a-695709ec017f": {"doc_hash": "bcca875fe233205010bd954808ee194c153d45450a51f3b7f7d4f0ce842b3df0"}, "8af5941f-5b46-41c0-abc6-8da065c06caa": {"doc_hash": "fd7a0970b6aa668d62ce6a17db2bf10f6fd990169325a0af2afadcc0b3ec564b"}, "0d7c7cab-cf39-4e28-9eb8-f1e0eca6f87f": {"doc_hash": "a98d8a7f51a45df67824ab2284f291ac98163626f7e892781ff84f64971b8407"}, "f3ccb2a3-1da8-4985-a1a0-66ed18fb4649": {"doc_hash": "1ecdee6f3b0ab1d7f31c39f2bd90743748b0a0a6d283cb10581a55eb4117929b"}, "eab0ec86-7081-443e-8585-6d84b44ef160": {"doc_hash": "0b4a11728b69bfc3773681cb39a2b8ed0dfd96f02834fc55cc4728095e5e5522"}, "dcbdf637-2f86-4213-a983-6484e97a8bef": {"doc_hash": "1a0a8274283e37a1b5e65f362875a5cdc402799c20e699a6c0d6223cb084740f"}, "c89d44c0-5231-4a99-a127-84669253d9f5": {"doc_hash": "ba85732c739a3dfea6ce9ea0bd0a2ae1eec7165343aabb48e991a88d23163ac8"}, "9df2d037-0c78-42bd-a80c-b6f10729eb6b": {"doc_hash": "af56a585e7add11430558ee1d753b38ad5818778967612bb66c0a83fe319379c"}, "ac0ecd7b-e0a5-43d4-822b-fa3b7e19541c": {"doc_hash": "2e43a7a21de015014fc470d2933fa94c0393eeb8c80d6ccd01eff29b512c219c"}, "342f02af-19be-481e-a762-bd54cbd6464c": {"doc_hash": "c9a07eff8d1acacf2e1c63debde41708f7ac9a6b8eda1bed8ec58bf70cb593ec"}, "578a20fe-05a1-47c9-a58d-07f7029986fe": {"doc_hash": "b33821ff27b344d7d77bb3f2122e059fbdae6674953e7efe6945507e44ef62f9"}, "0d96c4d6-9404-44da-b87b-bb310a4a6694": {"doc_hash": "71ad8edb342bb211803d1c444cdfca70cfdf52d357f479f592f896c1cea07c97"}, "44f26369-687f-4c4c-8149-0d570b676547": {"doc_hash": "bb22c2433e3cd819a110f3f2f7fb10abbaaeb2df16d7ab39eaec7503c9581214"}, "59e3b741-a657-49b4-905f-664fc31f0409": {"doc_hash": "789a295f094713c6a323eb93b403be93fa23f2fe1011006a0a4ac70ad2542b3b"}, "cbfda14e-dd9f-4270-abb4-8539347e4cae": {"doc_hash": "3ec2543f2483e29a1de3534b46e7213a89be89cbcdf23087e7de50b023b11117"}, "40250962-cf23-460f-aa5c-bd7326ac994d": {"doc_hash": "002dd66e7cd0684e57d2c71fb9370832a102dbcd1645d9b75e0733a19a55cff2"}, "c516dd34-98ac-4351-9af2-39ef786cc21d": {"doc_hash": "8f859679fe4c27480996f3c39818da9de19e9bd18c08ea7c7fb2ea70000b3424"}, "08372dfa-cc9b-4766-9744-c4f254d71496": {"doc_hash": "2c096d6103e70b11be97e97c9cb06a5322e927f244161e124fac54ef34bc1791"}, "4adc2e34-c323-4d73-91dc-986751971762": {"doc_hash": "085c58a4f9730281d9abed3144138adcb644b8991f96003eec4de21abc9504f7"}, "3382fef1-c1e6-4526-b075-ccbe2062fb38": {"doc_hash": "05d7a10f38b7183ec3745bdf9f9fe0f8e0a258fe66bb95ae5bd2d77246aabb17"}, "36254416-8c36-4133-9573-7a3e1b9682d9": {"doc_hash": "794bb906e68f6eb42a8b57774f0e7a3b7141fe287ff665b1ed7a31a6a1129dcc"}, "8130645e-99f9-4570-badf-812837a2cf14": {"doc_hash": "9f373b83b66feb2df52a738178b39844b330679cf348eac8c9c5d6190143f096"}, "815005eb-bca9-4bb2-9287-9374b3fafb58": {"doc_hash": "35a6b7858e2d7ec55f606874c1f613bb3a0fe603f9b7c5e3308f56c8d335c2b4"}, "97d46174-7527-4256-a8b0-ae50db7da584": {"doc_hash": "3c86c37bfa3149d198e0a5d12d7abd0844543aaa9c5c06c11a0feea1fbad4535"}, "7c757468-22ca-48fe-80a6-53391bb2b2f7": {"doc_hash": "747eea3e4d1f3b85dc436d31907677c33bc69acc19a8eb2f11bead473d77ac7f"}, "d4814264-a76b-4782-a5e1-7f078f6f3c70": {"doc_hash": "6b1c54f53a78de218c7fbb702e2a315a372acbdf9e9d95ad060e0c6edaf582f6"}, "cdcd5a93-c64c-47c3-b3ba-5f922880988c": {"doc_hash": "39f81223a6a01687118801ce5d6ade49e8b1f598b5492a3eaa8e4f5ae108d57a"}, "fe4f6dbb-c201-41aa-bcd2-9689b311b6d8": {"doc_hash": "0a186f929482349b741cc94d0a64c59b18eb2d85d2f5e070632ecabd9e05af2f"}, "2a3c8742-3200-49f7-95d4-9e686f0ed303": {"doc_hash": "80b7f5d7db0680422c76078bef9d94c06032a21ea76b05f751c3e5f6ba166c81"}, "73796437-2f75-4451-be44-7d2167a658e2": {"doc_hash": "e4ef028d8e2167dcfec423961255d31097da7445586d0e929063efce9eb27ab9"}, "b64181ca-cf8c-4f47-b773-3c34b8df313d": {"doc_hash": "016dd8b53cf59693edcc1fc1a55824ac234e1822934ac07ef9d46982fe51b925"}, "a11333f7-0930-4696-9b4a-2cfd34a6b6e9": {"doc_hash": "a97ef4b13ac6e1270924874d5c46f8cc631f34c904097ac4b9f366ff2197e979"}, "875ff207-302a-4779-867e-c447d8c89d8f": {"doc_hash": "219703d31430f1a9973f6c7c26a12aa797f5958f4017989dabe05b30f3c9c164"}, "0691a233-b99c-435e-a986-dee90b3e4e27": {"doc_hash": "15be8ac9c19ffab1278dfba57e21edc1788a02b9e5ebe7c58d01df4093faa02d"}, "6277cc64-14a2-44b0-b6d9-a674c31b4e2f": {"doc_hash": "c086f26dacc50f9336a88878944e23c3af6cb9ab6868891d5183a39bd2ae1988"}, "995ae667-ff68-49a9-a0d1-871fba7339d3": {"doc_hash": "d257adc678f4d1fc170f95def19f18fc118e93631544a7a3473dd7ff69234d81"}, "95759b02-6e6e-4fdc-9a35-d68ec490182a": {"doc_hash": "5dc6dcb3d9f38847c4e2f27e4f80de019aee85a80f33074e28ae7ee461368a92"}, "ae756392-93c1-44b5-9773-c032fa736c52": {"doc_hash": "958592970d1384e5af1246804ebfa6276fda8a1868d34f61203ea328a6d2fdc4"}, "a0a73669-5a48-49d7-a9a5-d25b35803954": {"doc_hash": "0ce41f743359de59a6465d4e13e7e04ae958962eadffa7430ae8c4db8b2dccae"}, "89fc560d-cac6-4450-bd42-542faffb37bf": {"doc_hash": "f3c9a57b15b08a0086fc05b066b7516917d5c8c114bbb7ab2571e9bc974990b1"}, "59d97930-3f0f-40e5-9002-5a4959c59353": {"doc_hash": "b9993422268fc6f621dd405d6884bf8232491c314eb13931aaa96fe3e79992b9"}, "49a55a9b-b979-4bc1-8979-2569955f2572": {"doc_hash": "766df0585e4543b3482334f78f453331f057e3771a7a259863a27c0c9fccb9ab"}, "5b96d7e4-f706-4eff-9c2f-5e607c792260": {"doc_hash": "b03988abc5ed24b15b2be62262d8e97c9656b1ecf9c3aca7aec41b95a8b01bcf"}, "863be920-cf77-42cb-8a7d-e5ece91ca410": {"doc_hash": "9eb769c013b6f4a7e31256ba04445bd5f316a3199b0982b5bdf7bedcb66d9c16"}, "be68e1eb-7944-4469-a31d-0d31dd1752a6": {"doc_hash": "9b2b54fb88b8bc62f1f9bd9e6e35d72260209be022092e46099fee6e9e7f3006"}, "de2c4b25-b6c7-4657-b1c1-e650f4777643": {"doc_hash": "4a876c4f6e5f9f0bc7d8f2ccda1fc63e946189e7960fb9b486c4ae0c07246eb1"}, "0790e3d6-c697-4f3e-8ced-fbe9cea7dd7d": {"doc_hash": "38fa514534f2f4d341017f37b0bce1eed487d19ab43db463c1dc44344841d897"}, "0b047e10-456c-494a-a18c-4c63011c4c55": {"doc_hash": "5fa2dc72b2b9593066394be7e4f73e959d6a0c4edf697906660af7672a68c43f"}, "e8eb1674-1c19-4323-800f-5e7552dc34d3": {"doc_hash": "a2e2066530835620ed4137c3fc4ac83e795354e5c6ab4a02e7fd54816f0c72e6"}, "884c7614-8e49-475e-a3c8-e517b360e118": {"doc_hash": "25ff09b0e23d47cafc718f75ac374ad66284b92747cca17c97b54759f9ea5fe1"}, "13c430e0-562d-4bf2-99d6-43a4e8363188": {"doc_hash": "b169b298d34447df8c420e076dd1e99574eb7a8ce625a761ec9164aaab0e288c"}, "a6ffabd5-6683-4291-9417-5573858c75be": {"doc_hash": "108b7a9cfe815f2d7e73e3dfd6ef519e27c4c5335a1610d481f5379c011e9426"}, "12afc639-c882-4f6e-9018-24fff185be63": {"doc_hash": "51877aac883219d7fe86eb4451774bae868c75f85625eaf784b136579697f9fd"}, "269146dd-5b52-425a-b846-c8323bbb01d4": {"doc_hash": "67164d6c1994201e98146acc88e152dc3249daeb449027022b5f0e00bb09084a"}, "8a291e38-f5fb-41f8-a1e6-71fcc12c7bfa": {"doc_hash": "f9e6388651bd0c5522b473dcd6db0885be2329904fdd1d915fb4724e6b676667"}, "465a28a3-c8ab-46cb-93b4-00bb84938f75": {"doc_hash": "432ffcd2bcfc24c7c81fb8e77390358099ca0ae354ba0fb814ac8399dd2fe945"}, "f38c24f7-3e2b-4c3d-a808-16007525ac1e": {"doc_hash": "84e5ad42f2c8bbefeaae2c3176c3502b24b6b5faac93885b4d93f1b7c09b798f"}, "104649c5-7beb-4e6f-808f-c6c6c70e9159": {"doc_hash": "b44f8aedbbab26dce5fc6d6ace22924d63a98cbe8d124571e454ccb8f408905e"}, "9a0a5cd3-bb90-4258-90f7-ab37035bb790": {"doc_hash": "9ae55a6cedd253347c90246983970890837e94c0abeadceb4d529c932e52e053"}, "c6dda3e3-0a0e-4c47-a17d-506844ed5f1a": {"doc_hash": "ba6824e7716b9e49ce3d752844bab8c35eb5b4ae68ad3dee21e32406c63226c8"}, "84a82939-8571-4f50-ab99-fb40bd13fe97": {"doc_hash": "60911afebd4e8be9bb7f4dc1f43f50f02819f0467f4cb4409c8bebc3d5268c41"}, "e939d002-ce8c-476d-b93b-08d49e817222": {"doc_hash": "b6c190d2762d3d92e1fc25cd07cf4ede566abe964c8519544ce8ace3b628a2b4"}, "0fb22452-2cdc-48fc-b6f3-bf92d1069dfe": {"doc_hash": "6c8083b2660fc8d4d32b0a4bd6439a7de02498b2ca8e0b684f9ea40fcdeeb6c9"}, "cae2df13-1ccd-4524-bdf7-8f43fca04812": {"doc_hash": "8749bdc6bbe31726957816e2a7bb15919a73ceb661c9f658bd6d2ad08d0d56f6"}, "f81e0bd3-0bd8-4c76-8f9a-942b5f3eb40f": {"doc_hash": "4d37c7875ec4af5b935a4833a7fb511b3c2b385c06dd6d75d8c8ad451d883c02"}, "2b2454ba-2a84-4490-b835-a76e89faece6": {"doc_hash": "c279d392f2c0cafb2bda579f28c306b37aaa439367366977e9cf8915efe9dd8a"}, "d20b36ef-fbf5-46a3-a1d5-57da77342573": {"doc_hash": "66badfd76d983b7f15c6c9d99e4423e11413a0c8479f521e3335a0684f6b5e25"}, "aa428afe-0ee7-4757-8f5e-96eadcf191be": {"doc_hash": "2c317e51841f2cac230e1f4fb2712e13eec029607d379fccf725b258c43df461"}, "7c547ec5-a163-4f1e-91ef-f37ae1254778": {"doc_hash": "e8c673550fb1f1eb8ab786965d9709b2c622cf7e6b6e6877bb18815dc58e4eab"}, "d3b29716-0c2e-4b00-8a22-5fc1673af04b": {"doc_hash": "79a319149b627288314a2b0c97cf3d67217a5b4f91ae77c697b19f2f69431b53"}, "a9b83356-53a7-45ec-af57-cf714286ce2a": {"doc_hash": "a5f9748a7ea55f1f597e8bd08e3fe6f417518d4e1923fde3575abb95ce8a2c27"}, "af6795e9-7220-4df6-8b9d-4a3b30e635b7": {"doc_hash": "bb545bc76bd14510885abb9712c0004ed7fa9b50e09b7053a039db5857439fe2"}, "c1214439-5a89-4606-967a-0e0dd8f81f3a": {"doc_hash": "0bf150175fb4e93529877a2cd3b41148b007213e6969eef7e226b7553237ea3b"}, "40647e1a-cfdd-4caf-bf5a-4800e91c32ea": {"doc_hash": "2e2a2a9dd948df4b68d5e0e6cc2e045cb78f3f960bdc3af3b1d5312f7eea3aa9"}, "6627abff-fbdf-437a-a9d1-bb383554a063": {"doc_hash": "fd4501ca5bf18b4ad1921b2f65ff187edcec7aa37733a942b9b10a167464eee5"}, "a5435533-d92c-43d8-a5aa-0a5fed54c098": {"doc_hash": "a079462cb1a0cebb7d05f9bfe45f0f8bcc666f4217f36303f41b53eb0426f1e8"}, "a1d004b8-c5ca-4f1d-ba37-dbb71a4fab41": {"doc_hash": "05ed150ae150899149fae9aa6f493fb6eebda4d03e24dda6e31bd6eea3455e05"}, "5923cbea-6104-4217-83e4-8939801076c3": {"doc_hash": "0ed3a154e1944e6d737d71a38ce412fb39ec920775aeb228c407bac3c4c37754"}, "6899b2df-0359-491d-b727-6b974db86bfd": {"doc_hash": "ead9b0ccbac26fdaf6d44654b15d99663b2fbbd64f64fe552d6e0204890044b9"}, "2f9403db-f6eb-414f-a122-61a99a958999": {"doc_hash": "7645ed8a1799d653bfccd8071d4b334cea2b5982902e28bd491c261aa4aa99e8"}, "62641cda-9abd-4725-b6e3-af5a9cd90e2b": {"doc_hash": "d07d961758b90f92eb4448d0219ece8a9fccd548e25d3f359eb7ba6360d739a4"}, "859206aa-6453-4fce-af88-7a71b327324e": {"doc_hash": "ea111962282b0c5c3b400e6157304fdb0d12315b8db3d7b01c8edeaf08059a90"}, "14af71e5-d868-4def-beae-ac1d87f4453a": {"doc_hash": "c5e092377621eed0f255342cae514ea24877d3dbb0da758b886e260edd545596"}, "8d7047da-27e4-4e37-95e3-14b9ec833b16": {"doc_hash": "763e5810f5bf37d9999d5dcdb35fc0bd10048e47bff8c616f3a1c82499f7449a"}, "3c064289-01af-4057-9acd-72764b5a19fa": {"doc_hash": "f781582f5aa49ce2eefc25a08a261258a6aae142bba9179d92fc395ee6dc93dc"}, "137533b9-10eb-47ae-9cb2-06a2705d8958": {"doc_hash": "28ac4acbcac2e25affecc443a3033e3aa99a903ce034e05610736efb8b764e91"}, "f10fa093-172c-4bd5-9c37-23e933cf7d8a": {"doc_hash": "d7719f5191b1db72c480f6f5ff26dbea3ce6f705384a4de64f9970fb06c49ae4"}, "a9700d84-5150-4f28-bc85-4626d0a8f8eb": {"doc_hash": "0b94b7a3a602657d73ffd3730fbe53cdcce51ece285ac1713d0743810700ccd5"}, "c48bb421-bf6e-4f48-9a7c-07a4c2710907": {"doc_hash": "b3a31c073482b4e8bb2c32164fc8c3874036582e8c718166fd9f0ba5383b5741"}, "6f27a8db-f5dd-472c-a086-fd3c94bf9826": {"doc_hash": "12029ec7c2739a049ab39fae722f2e1b9879ebd3186a523bd1935131cfd317a4"}, "34658486-80ee-4f4d-ad0a-89b5783f3246": {"doc_hash": "bcca875fe233205010bd954808ee194c153d45450a51f3b7f7d4f0ce842b3df0"}, "47214ed0-9449-489f-9ab2-865eaf228313": {"doc_hash": "fd7a0970b6aa668d62ce6a17db2bf10f6fd990169325a0af2afadcc0b3ec564b"}, "33db5f2b-8dbb-47ae-a20d-5f3ecc869538": {"doc_hash": "a98d8a7f51a45df67824ab2284f291ac98163626f7e892781ff84f64971b8407"}, "5221b705-81e3-4dc9-92d1-9b833d2702f5": {"doc_hash": "1ecdee6f3b0ab1d7f31c39f2bd90743748b0a0a6d283cb10581a55eb4117929b"}, "40a0a193-2045-4e30-a8ad-ef3f12e2e432": {"doc_hash": "0b4a11728b69bfc3773681cb39a2b8ed0dfd96f02834fc55cc4728095e5e5522"}, "ee685157-1739-4a8d-a18b-ddb4bb5bb124": {"doc_hash": "1a0a8274283e37a1b5e65f362875a5cdc402799c20e699a6c0d6223cb084740f"}, "5866dc58-9abb-4faf-ae4a-674d7ea2ec0a": {"doc_hash": "ba85732c739a3dfea6ce9ea0bd0a2ae1eec7165343aabb48e991a88d23163ac8"}}, "docstore/data": {"9df2d037-0c78-42bd-a80c-b6f10729eb6b": {"__data__": {"text": "DevOps Self -Service Centric GitHub Actions Workflow Orchestration  \nHow to orchestrate GitHub Actions workflows driven by image immutability  \n \nDiagram by author  \nGitHub Actions  \nThe adoption of GitHub Actions has been increasing in recent years. According t o a survey by \nThe Software House  for the state of frontend, GitHub Actions takes the front seat in CI/CD tools, \nwith over 56% in 2022 compared to 35% in 2020. This shows that more developers shi fted to \nGitHub Actions as their CI/CD tool in their day -to-day. \n", "doc_id": "9df2d037-0c78-42bd-a80c-b6f10729eb6b", "embedding": null, "doc_hash": "af56a585e7add11430558ee1d753b38ad5818778967612bb66c0a83fe319379c", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 528}, "relationships": {"1": "efec9943-e9f3-4fb3-97d5-3d3c43b186da"}}, "__type__": "1"}, "ac0ecd7b-e0a5-43d4-822b-fa3b7e19541c": {"__data__": {"text": " \nImage source:  https://tsh.io/state -of-frontend/  \nGuided by the  DevOps self -service pipeline architecture , we explored  Terraform project \nstructure and its re usable modules  in our previous story. This article will dive into how to \norchestrate application pipelines with GitHub Actions. We will focus on the red \nhighlighted rectangle in the diagram below.  \n", "doc_id": "ac0ecd7b-e0a5-43d4-822b-fa3b7e19541c", "embedding": null, "doc_hash": "2e43a7a21de015014fc470d2933fa94c0393eeb8c80d6ccd01eff29b512c219c", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 369}, "relationships": {"1": "0d2a1c0e-3ec6-4148-9249-476234bbd548"}}, "__type__": "1"}, "342f02af-19be-481e-a762-bd54cbd6464c": {"__data__": {"text": " \ndiagram by author  \nGitHub Actions Reusable Workflow  \nIn DevOps\u2019 self -service centric practice, reusability is key. Just like reusable Terraform \nmodules, we can have reusabl e GitHub Actions workflows in our application CI/CD \npipelines.  \nFrom a stateful/stateless perspective, reusable workflows are stateless. Caller workflows \nfrom many different applications can call one reusable workflow.  \nI published an article a few months ag o titled  A Deep Dive into GitHub Actions\u2019 Reusable \nWorkflows , in which I explored the detailed steps to m ake a GitHub Actions workflow \nreusable, how to call a reusable workflow, and how to pass input parameters and secrets \nto the reusable workflow. Sample code was shared in that article, and it is listed at the \nbottom of this article. I highly recommend you l ook at that article if you are new to \nGitHub Actions\u2019 reusable workflow.  \n", "doc_id": "342f02af-19be-481e-a762-bd54cbd6464c", "embedding": null, "doc_hash": "c9a07eff8d1acacf2e1c63debde41708f7ac9a6b8eda1bed8ec58bf70cb593ec", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 887}, "relationships": {"1": "5fc9bb01-c198-4beb-971e-c4e38fdb105e"}}, "__type__": "1"}, "578a20fe-05a1-47c9-a58d-07f7029986fe": {"__data__": {"text": "Once you start using reusable workflows in your projects, you will never look back, as \nreusable workflows save so much time and effort in rolling out your apps\u2019 CI/CD \nworkflows and el iminating maintenance headaches.  \nContainer Image Immutability  \nContainer image immutability refers to creating and using container images that cannot \nbe modified after they are built. Once an image is built and pushed to a registry, it should \nnot be modifie d. Instead, a new image should be built with any desired changes and \ndeployed.  \nThe main benefit of container image immutability is its predictability. When image \nimmutability is enforced, you can be sure that your application behaves as predicted \nacross en vironments such as staging and prod. Image immutability also offers you the \npeace of mind to roll back to a previous image tag in case of errors because you know the \nprevious image tag is immutable and has not been tampered with by builds after its \nrelease . Overall, immutability helps in ensuring consistency, security, and reproducibility \nof container images.  \nImage Immutability Challenges  \nTriggering CI before each CD for each environment does not guarantee image \nimmutability. Why? Each CI could produce a different image even though you have not \nchanged your source code. If you have dependency upgrades and auto -merge automated \nby tools such as GitHub dependabot, your source code varies depending on when your \nlatest dependency upgrades took place. Because of that, the image built a week ago and \nthe image built today could be two different images despite no manual code changes in \nbetween.  ", "doc_id": "578a20fe-05a1-47c9-a58d-07f7029986fe", "embedding": null, "doc_hash": "b33821ff27b344d7d77bb3f2122e059fbdae6674953e7efe6945507e44ef62f9", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 1627}, "relationships": {"1": "d2cbbbfd-5a41-4cb2-b0e6-9a7626976fd4"}}, "__type__": "1"}, "0d96c4d6-9404-44da-b87b-bb310a4a6694": {"__data__": {"text": "To en force image immutability, we have to separate CI from CD, making them into two \nisolated workflows. CI builds and pushes the image to ECR, and CD needs to be smart \nenough to know exactly which image tag to use to pull that immutable image. Teams who \nhave be en used to using date timestamp or Git SHA as part of the image tag now face a \ndilemma: how do you know which image tag to use when you trigger CD?  You could try \nto trace your CI workflow debug log to figure out what image tag was published to ECR, \nbut it defeats the purpose of automation. Any manual effort in this flow is not a desirable \nsolution.  \nIt ultimately boils down to \u2014 how do you ensure your image tag is immutable?  \nRead on to find out.  \nMaven Release Automation  \nAssume you are developing a Spring Boo t app using Maven as a build tool, and your app \nwill be deployed to three environments: development, staging, and prod. Maven Release \nautomation is the key to maintaining container image immutability. Let\u2019s take a closer \nlook at how Maven Release works.  ", "doc_id": "0d96c4d6-9404-44da-b87b-bb310a4a6694", "embedding": null, "doc_hash": "71ad8edb342bb211803d1c444cdfca70cfdf52d357f479f592f896c1cea07c97", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 1050}, "relationships": {"1": "1c0d1f46-032b-400c-b0a4-8544a4aa3565"}}, "__type__": "1"}, "44f26369-687f-4c4c-8149-0d570b676547": {"__data__": {"text": " \ndiagram by author  \nThe diagram above should be pretty self -explanatory. Maven Release automates tag \nrelease and bumps up pom version to the next deve lopment version. If you express the \nabove Maven Release flow in a GitHub Actions reusable workflow, you\u2019ll have the \nfollowing sample release workflow.  \nThe key steps in the above workflow are:  \n\u2022 Line 57 \u201362: this is where the magic takes place by Maven Release , simply \nrun mvn -B release:prepare release:perform , Maven Release \nremoves your snapshot from your pom version, tags the release version, \nreleases your artifact to artifact registry such as GitHub Packages, and bumps \nup to the next development version. Tha t one single command triggers all \n", "doc_id": "44f26369-687f-4c4c-8149-0d570b676547", "embedding": null, "doc_hash": "bb22c2433e3cd819a110f3f2f7fb10abbaaeb2df16d7ab39eaec7503c9581214", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 718}, "relationships": {"1": "94e58f55-8e6c-4dfd-8d88-442641245808"}}, "__type__": "1"}, "59e3b741-a657-49b4-905f-664fc31f0409": {"__data__": {"text": "actions. Notice line 62, a retry logic has been added to minimize peak load \nGitHub throwing 500 internal server error. This is a workaround \nrecommended by GitHub tech support when I ran into such an error before.  \n\u2022 Line 52 \u201355: this step creates a git user to push to GitHub automated pom \nsnapshot release, next version bump -up, etc.  \n\u2022 Line 64 \u201366: in case of failure during Maven Release, the step will roll back \nMaven Release by command  mvn -B release:rollback . \nKeep in mind that Ma ven Release version is immutable. So, how is Maven Release \nrelated to container image immutability? You guessed it \u2014 release version number as \ncontainer image tag! How does that work exactly? Let\u2019s continue the exploration.  \nGitHub Actions Workflow Orchestr ation  \nLet\u2019s say you have developed/compiled a list of stateless reusable workflows for your app \nfor CI, CD, and release. How do you tie these workflows together so they can be \norchestrated to compose that masterpiece tune for your CI/CD?  \nLet\u2019s start with this wo rkflow orchestration diagram below:  ", "doc_id": "59e3b741-a657-49b4-905f-664fc31f0409", "embedding": null, "doc_hash": "789a295f094713c6a323eb93b403be93fa23f2fe1011006a0a4ac70ad2542b3b", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 1064}, "relationships": {"1": "b38ccd80-2127-4124-a3ce-6c8c8880341d"}}, "__type__": "1"}, "cbfda14e-dd9f-4270-abb4-8539347e4cae": {"__data__": {"text": " \ndiagram by author  \nCan you hear there is a symphony going on? : -) Let\u2019s trace  through the steps:  \n1. When you raise a new pull request during active development, it auto -triggers \nyour CI workflow.  \n2. The CI workflow does the build, test, docker image build, and push to your \ncontainer registry, such as ECR, and it also completes the image scan for \nvulnerability. Please note that the image tag here uses the project version \ndefined in your application pom.  \n", "doc_id": "cbfda14e-dd9f-4270-abb4-8539347e4cae", "embedding": null, "doc_hash": "3ec2543f2483e29a1de3534b46e7213a89be89cbcdf23087e7de50b023b11117", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 473}, "relationships": {"1": "331cc524-546f-4571-9301-55cf3aa2e4ce"}}, "__type__": "1"}, "40250962-cf23-460f-aa5c-bd7326ac994d": {"__data__": {"text": "3. After multiple rounds of PR review and code fixes, your PR finally got \napproved, and you are ready to merge your PR to your default branch . Upon \nPR merge, it auto -triggers your CD workflow.  \n4. The CD workflow pulls your docker image from the container registry and \ndeploys it to your predefined destination, such as ECS.  \n5. After many iterations of development, your app is ready to be promoted to \nstaging environment. You create a release branch for a release candidate (RC) \nversion, which triggers the release workflow to automate Maven Release.  \n6. RC artifact gets published to GitHub Packages or any other artifact registry of \nyour choice with proper conf iguration in place.  \n7. Once Maven Release is successful, you need to trigger CD workflow to deploy \nthe RC version to Dev via the manual trigger, where you can select the dev \nenvironment and the tag (not the main branch). Notice you need to select the \ntag in t he dropdown, which was just released by Maven Release at step 6.  \n8. CD, in turn, triggers the CI workflow as you now need to build the new RC \nversion image.  \n9. The CI workflow does the build, test, docker image build, push to ECR, and \nscans images for vulnerabil ity. \n10. CD pulls the RC version image from ECR and deploys it to Dev.  \n11. When you deploy the RC version image to Staging, you trigger CD via the \nmanual trigger by selecting Staging env and the RC tag (not the main branch).  ", "doc_id": "40250962-cf23-460f-aa5c-bd7326ac994d", "embedding": null, "doc_hash": "002dd66e7cd0684e57d2c71fb9370832a102dbcd1645d9b75e0733a19a55cff2", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1441}, "relationships": {"1": "3c6c1455-49b3-42c5-a734-e61f987987e0"}}, "__type__": "1"}, "c516dd34-98ac-4351-9af2-39ef786cc21d": {"__data__": {"text": "12. CD pulls the RC version image from ECR and deploys it to Staging. Steps 5 \u2013\n12 could iterate multiple rounds depending on your application development \nstatus, bug fixes, etc., until you are finally ready to release the final version \n(without RC). Go through steps 5 \u201312 to release your final release version and \ndeploy it to Dev and Staging.  \n13. When you deploy the release version image to Prod, you trigger CD via the \nmanual trigger by selecting Prod env and the final release tag (not the main \nbranch). I suggest hav ing GitHub deployment protection rule configured to \nensure proper approval chain takes place before the Prod deployment can be \nactually triggered.  \n14. CD pulls the release version image from ECR and deploys it to Prod.  \nA few key observations:  \nCI workflow is on ly called twice in this whole lifecycle. The first is from PR \ncreation/merge during the active development phase. The second call is from the CD \nworkflow after the Maven Release, which has removed the snapshot, CI workflow is \ntriggered to build the RC vers ion image or the final release image, which gets deployed to \nall environments.  \nYou could have multiple iterations of snapshot image push and RC version push, but \neach Maven Release will be incrementing their numbering for RC version or release \nversion, mak ing each of such release version immutable. With the Maven Release, it\u2019s \nguaranteed you can not release the same version (whether RC or release version) to your \nartifact registry twice. Otherwise, you will be running into a 409 error.  ", "doc_id": "c516dd34-98ac-4351-9af2-39ef786cc21d", "embedding": null, "doc_hash": "8f859679fe4c27480996f3c39818da9de19e9bd18c08ea7c7fb2ea70000b3424", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 1560}, "relationships": {"1": "2b4cba27-36e3-4c6a-b199-e713e009eb0f"}}, "__type__": "1"}, "08372dfa-cc9b-4766-9744-c4f254d71496": {"__data__": {"text": "Maven Release Candida te (RC)  \nDuring multiple Staging deployment rounds, you should not keep bumping up the patch \nrelease number in your Semantic Versioning (SemVer, major.minor.patch). The release \ncandidate (RC) version is introduced for your Staging deployments for as many ro unds \nas needed without impacting your SemVer when your app is released to Prod.  \nLet\u2019s take a different angle and look at how those RC versions are managed between the \nmain branch and your release branches. Hopefully, it gives you a better idea on how \nMaven  Releases ties into container image immutability.  ", "doc_id": "08372dfa-cc9b-4766-9744-c4f254d71496", "embedding": null, "doc_hash": "2c096d6103e70b11be97e97c9cb06a5322e927f244161e124fac54ef34bc1791", "extra_info": {"page_label": "11"}, "node_info": {"start": 0, "end": 596}, "relationships": {"1": "0c59fad0-d09c-4591-907e-9f2a91c4251c"}}, "__type__": "1"}, "4adc2e34-c323-4d73-91dc-986751971762": {"__data__": {"text": " \ndiagram by author  \nImage Immutability Implementation in Action  \nAs you can see from the orchestration diagram abov e, there are three workflows \ninvolved:  ci.yml , cd.yml , and  release.yml . These workflows are all caller \nworkflows, which calls reusable workflows. Let\u2019s take a look at what the caller workflows \nlook like:  \n", "doc_id": "4adc2e34-c323-4d73-91dc-986751971762", "embedding": null, "doc_hash": "085c58a4f9730281d9abed3144138adcb644b8991f96003eec4de21abc9504f7", "extra_info": {"page_label": "12"}, "node_info": {"start": 0, "end": 333}, "relationships": {"1": "425983d7-9f85-4957-aac1-a11a5a0fd830"}}, "__type__": "1"}, "3382fef1-c1e6-4526-b075-ccbe2062fb38": {"__data__": {"text": "ci.yml  is straightforward with no tricks. It is a si mple workflow calling a reusable \nworkflow, and it\u2019s triggered by creating a PR or pushing code into the PR.  \ncd.yml  is a bit more involved. See the following reasons:  \n\u2022 It\u2019s triggered by either a PR merge (in dev) or a manual trigger.  \n\u2022 If it\u2019s for dev environment or PR merge, it also triggers the  build-and-\ntest  job, which is what CI workflow does. Why do we need this condition \nand job in CD workflow? The dev environment will be constantly updated \nwith the latest image, which would have t he SNAPSHOT in the pom version. \nIf we don\u2019t perform the  build-and-test  step before the  deploy-to-\necs step, there is no guarantee that developer A\u2019s image will not be \noverwritten by developer B\u2019s image, as they both share the same image tag, \nthe SNAPSHOT ve rsion.  \n\u2022 If it\u2019s for environments other than dev, the  build-and-test  job gets \nskipped because of that conditional statement on line 22 (see below the code). \nLine 34 ensures this  deploy-to-ecs job is run only when PR is merged in \ndev, or for other environment s via manual trigger, and PR is not raised by \ndependabot. This is where the image immutability implementation is in \naction. Take a closer look at the orchestration diagram above. Staging and \nProd only trigger CD workflow, which pulls the RC or release vers ion image \nfrom ECR and deploys it.  \nHow does CD workflow know which version number to use as an image tag? Look in our \nCI and CD reusable workflows, where  PROJECT_VERSION  is discerned from the code ", "doc_id": "3382fef1-c1e6-4526-b075-ccbe2062fb38", "embedding": null, "doc_hash": "05d7a10f38b7183ec3745bdf9f9fe0f8e0a258fe66bb95ae5bd2d77246aabb17", "extra_info": {"page_label": "13"}, "node_info": {"start": 0, "end": 1554}, "relationships": {"1": "78386276-c367-40c7-a874-db9deabfbbd0"}}, "__type__": "1"}, "36254416-8c36-4133-9573-7a3e1b9682d9": {"__data__": {"text": "checked out (branch code for Dev env and tag code for Stagi ng and Prod) by running  mvn \nhelp:evaluate  to extract its project version and then configure it as an environment \nvariable for the image tag push and pull.  \n- name: Set project version as environment variable  \n  run: echo \"PROJECT_VERSION= $(mvn help:evaluate -\nDexpression=project.version -q -DforceStdout) \" >> $GITHUB_ENV  \nrelease.yml  is again really straightforward, triggered by either manual trigger or the \ncreation of a branch with a naming convention starting with  release/ . After that, \nperform a simple call to the reusable workflow. See the sample below:  \nThis concludes our workflow orchestration driven by container image immutability. I \nwould love to hear any feedback to improve this orchestration. If you have a different way \nof handling wor kflow orchestration with image immutability, leave a comment for our \nreaders and me.  \nAll sample code can be found in my GitHub repositories:  \n\u2022 https://github.com/wenqiglant z/reusable -workflows -modules  \n\u2022 https://github.com/wenqiglantz/customer -service -reusable -workflows -\nexample  \nSummary  \nThis article focused on GitHub Actions workflow orchestration driven by container image \nimmutability. We explored multiple topics such as reusable workflows, image ", "doc_id": "36254416-8c36-4133-9573-7a3e1b9682d9", "embedding": null, "doc_hash": "794bb906e68f6eb42a8b57774f0e7a3b7141fe287ff665b1ed7a31a6a1129dcc", "extra_info": {"page_label": "14"}, "node_info": {"start": 0, "end": 1301}, "relationships": {"1": "229d3b60-4586-4716-8420-71fc18ed5c84"}}, "__type__": "1"}, "8130645e-99f9-4570-badf-812837a2cf14": {"__data__": {"text": "immutability, the benefits and the challenges of image immutability in the pipelines, \nMaven Release automation, and how to tie all workflows together in the lifecycle of an \napplication\u2019s CI/CD/release. I hope you found this article helpful.  \nI welcome you to check out the rest of the four parts in my five -part \u201cThe Path to DevOps \nSelf-Service\u201d ser ies: \n \nDevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \nA high -level architectural overview of the self -service pipeline  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Terraform Project Structure  \nHow to structure Terraform code and its reusable modules  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Security and Guardrails  \nA list of hand -picked actions for security scans and guardrail s for your pipelines, \ninfrastructure, source code, base\u2026  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Integration  \nSecret s management as the glue of pipeline integration  \nbetterprogramming.pub  \n \nHappy coding!  \nReferences  \n \nThe State of Frontend 2022  \nAleksandra D\u0105browska Report\u2019s Editor -in-Chief The last two years haven\u2019t been the \neasiest and prompted a lot of changes\u2026  \ntsh.io  \n ", "doc_id": "8130645e-99f9-4570-badf-812837a2cf14", "embedding": null, "doc_hash": "9f373b83b66feb2df52a738178b39844b330679cf348eac8c9c5d6190143f096", "extra_info": {"page_label": "15"}, "node_info": {"start": 0, "end": 1218}, "relationships": {"1": "2984c14c-c6a7-47b2-83be-f7e580e0a7f3"}}, "__type__": "1"}, "815005eb-bca9-4bb2-9287-9374b3fafb58": {"__data__": {"text": " \nTop 5 CI/CD Tools to L ook Out for in 2021  \nAutomation and continuous integration/continuous development (CI/CD) can have a \nhuge positive impact on how developers\u2026  \njfrog.com  \n \n \nBest practices for operating containers | Cloud Architecture Center | Google \nCloud  \nThis article describes a set of best practices for making containers easier to operate. \nThese practices cover a wide\u2026  \ncloud.google.com  \n \n \nWhy I think we should all use immutable Docker images  \n \n ", "doc_id": "815005eb-bca9-4bb2-9287-9374b3fafb58", "embedding": null, "doc_hash": "35a6b7858e2d7ec55f606874c1f613bb3a0fe603f9b7c5e3308f56c8d335c2b4", "extra_info": {"page_label": "16"}, "node_info": {"start": 0, "end": 475}, "relationships": {"1": "fe369b22-9247-495d-9d97-42f5c5dad7cd"}}, "__type__": "1"}, "97d46174-7527-4256-a8b0-ae50db7da584": {"__data__": {"text": "DevOps Self -Service Centric Pipeline Integration  \nSecrets management as the glue of pipeline integration  \n \nDiagram by author  \nBefore we dive into pipeline integration, let\u2019s take a look at the journey we have come \nalong toward DevOps self -service:  \n\u2022 Part 1:  DevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \n\u2022 Part 2:  DevOps Self -Service Centric Terraform Project Structure  \n\u2022 Part 3:  DevOps Self -Service Centric GitHub Actions Workflow \nOrchestration  \n\u2022 Part 4:  DevOps Self -Service Centric Pipeline Security and Guardrails  \nWe focused on one particular area in  each of those four parts of the DevOps self -service \nseries. The 3 \u20132\u20131 rule explained in Part 1 of the pipeline architecture fleshed out our \noverall path to DevOps self -service.  \n", "doc_id": "97d46174-7527-4256-a8b0-ae50db7da584", "embedding": null, "doc_hash": "3c86c37bfa3149d198e0a5d12d7abd0844543aaa9c5c06c11a0feea1fbad4535", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 781}, "relationships": {"1": "1373c2ef-1694-4c60-a74c-c22c9e0cd57d"}}, "__type__": "1"}, "7c757468-22ca-48fe-80a6-53391bb2b2f7": {"__data__": {"text": "In this story, we will focus on the \u201c1\u201d in the 3 \u20132\u20131 rule, the pipeline integr ation (see the \npart highlighted in red in the diagram below). This secrets creation automation is the \nglue that holds the infrastructure pipeline and the application pipeline together.  \n \nDiagram by author  \nWhat kind of secrets are we talking about, you ask.  \nThis is not the application secrets that belong in the secrets management tool of your \ncloud provider, such as AWS Secrets Manager.  \nThis is data from your Terraform outputs, which need to be consumed by your \napplication pipeline.  \nAfter Terraform GitHub Act ions workflow applies Terraform configuration, your \nresources are successfully provisioned in your cloud provider. With your infrastructure \nready, you can kick off your application pipeline to deploy your code into your newly \nprovisioned infrastructure.  \n", "doc_id": "7c757468-22ca-48fe-80a6-53391bb2b2f7", "embedding": null, "doc_hash": "747eea3e4d1f3b85dc436d31907677c33bc69acc19a8eb2f11bead473d77ac7f", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 867}, "relationships": {"1": "d69b4e5d-dc4f-4268-ac2f-a56814a0147a"}}, "__type__": "1"}, "d4814264-a76b-4782-a5e1-7f078f6f3c70": {"__data__": {"text": "In between these two steps, you often need to configure GitHub secrets to instruct your \napplication workflows to interact with your cloud infrastructure. This may include \nspecifying the S3 bucket name, so your SPA can be uploaded to the specified bucket, or \nfor backend microservices to be deployed to AWS ECS, configuring a bunch of secrets \nsuch as cluster name, ECS service, task definition, container name, etc.  \nYou may have been configuring these secrets manually after your infrastructure is \nprovisioned. Ther e\u2019s got to be a better way! That\u2019s where the pipeline integration through \nGitHub secrets creation automation comes into play.  \nTerraform is truly an amazing tool. Out of its 2800+ providers at official, partner, and \ncommunity tiers, one provider interacts with GitHub resources \u2014 the GitHub provider. \nThis provider will assist us in this secrets creation automation. Let\u2019s explore ho w to \nautomate these secrets creation/updates in your infrastructure pipeline.  \nStep 1: Add GitHub Provider To Your Terraform Configuration  \nThe snippet below calls the  cloudposse/cloudfront -s3-cdn/aws  Terraform module to \nprovision an AWS CloudFront CDN with an S3 origin.  \n\u2022 Lines 6 \u20139: add GitHub provider, which can coexist with the AWS provider \nfrom lines 1 \u20133. Notice GitHub provider needs \nboth  token  and owner  configured. We  will explain how to \nconfigure  token  in step 2 below. For  owner , enter the owner of your \nGitHub repository.  \n\u2022 Lines 30 \u201342: two GitHub environment secrets were created by calling the \nGitHub provider\u2019s resource  github_actions_environment_secret . ", "doc_id": "d4814264-a76b-4782-a5e1-7f078f6f3c70", "embedding": null, "doc_hash": "6b1c54f53a78de218c7fbb702e2a315a372acbdf9e9d95ad060e0c6edaf582f6", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 1609}, "relationships": {"1": "38a9c9ff-b438-4de9-91c7-d85959b0a7f9"}}, "__type__": "1"}, "cdcd5a93-c64c-47c3-b3ba-5f922880988c": {"__data__": {"text": "One secret is for S3_BUCKET_NAME , the \nother  CLOUDFRONT_DISTRIBUTION_ID . Notice we need to pass \nin repository  and environment  for this resource, which are fed in \nfrom the application pipeline. We will explore the details in step 2.  \n\u2022 Also, note that we pass the values for the secrets \ninto plaintext_value  on lines 34 and 41. For security, the contents of \nthe plaintext_value  field have been marked as  sensitive  in \nTerraform, but it is important to note this does not hide it from state files. \nIn our case, since we are only stor ing the S3 bucket name and CloudFront \ndistribution ID in the secrets, not any sensitive data such as a password, it \nis fine to store in  plaintext_value . \nFor sensitive values, it\u2019s recommended to populate \nthe encrypted_value . Whether you \nuse plaintext_value  or encrypted_value , it\u2019s best practice to \nextract fields from a resource or a data source as the value of a secret. In \nour case, we are getting the secret values from the outputs \nof module.static_site . \nStep 2: Pass Environment Variables From Terraform Git Hub Actions Workflow Into \nTerraform Configuration File  \nAs mentioned in step 1, we have three values to explore, which we deferred to this step. \nThey are:  \n\u2022 pipeline_token  \n\u2022 deploy_repo  ", "doc_id": "cdcd5a93-c64c-47c3-b3ba-5f922880988c", "embedding": null, "doc_hash": "39f81223a6a01687118801ce5d6ade49e8b1f598b5492a3eaa8e4f5ae108d57a", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 1269}, "relationships": {"1": "fddb99a6-073e-4759-ae24-517327a18cb6"}}, "__type__": "1"}, "fe4f6dbb-c201-41aa-bcd2-9689b311b6d8": {"__data__": {"text": "\u2022 deploy_env  \nHow do you define these values in Terraform GitHub Actions workflow? Read on.  \nPIPELINE_TOKEN : You need this token for Terraform to call the GitHub provider to \nauto -create GitHub secrets, such as  S3_BUCKET_NAME , based on the resources \nTerraform provisioned.  To generate the token, do the following:  \n\u2022 Go to  https://github.com/settings/tokens  \n\u2022 Press \u201cGenerate new token\u201d  \n\u2022 Be sure to assign the token \u201c repo \u201d scope and \u201c read:public_key \u201d scope \n(see screensho t below)  \n\u2022 Name the token  PIPELINE_TOKEN  \n\u2022 Copy the token value  \nTo add this new token as your repository secret, navigate to Settings \u2192 Secrets \u2192 \nActions \u2192 new repository secret. Create a new repository secret with the \nkey PIPELINE_TOKEN  and value what you jus t copied from above.  ", "doc_id": "fe4f6dbb-c201-41aa-bcd2-9689b311b6d8", "embedding": null, "doc_hash": "0a186f929482349b741cc94d0a64c59b18eb2d85d2f5e070632ecabd9e05af2f", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 785}, "relationships": {"1": "8b3f3a1b-7338-4a3e-9122-584c85d5e6b4"}}, "__type__": "1"}, "2a3c8742-3200-49f7-95d4-9e686f0ed303": {"__data__": {"text": " \nImage by author  \ndeploy_repo  and deploy_e nv are two environment variables configured in the \nTerraform GitHub Actions workflow; see lines 30 -31 below.  deploy_repo  refers to the \nGitHub repository this workflow runs from, expressed in GitHub context \nwith  github.event.repository.name . \ndeploy_env  refers to the environment this workflow runs for. This environment is \nselected from the manual trigger. If it\u2019s not selected through the manual trigger, it \ndefaults to  dev: github.event.inputs.environment || \u2018dev\u2019 . \n", "doc_id": "2a3c8742-3200-49f7-95d4-9e686f0ed303", "embedding": null, "doc_hash": "80b7f5d7db0680422c76078bef9d94c06032a21ea76b05f751c3e5f6ba166c81", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 528}, "relationships": {"1": "444001b9-6899-4de3-be0c-867d14a7dcc8"}}, "__type__": "1"}, "73796437-2f75-4451-be44-7d2167a658e2": {"__data__": {"text": "Now that these environment variables are in p lace, how do we pass them to Terraform \nconfiguration files? Notice the Terraform plan step, lines 105 \u2013107. First, we \nconvert  DEPLOY_REPO  and DEPLOY_ENV  to lowercase via an expression such \nas ${DEPLOY_REPO,,} , and then pass the lowercase values to Terraform  as its \nenvironment variables, which always start with  TF_VAR_  as their prefix.  \nNow, let\u2019s look at how those environment variables injected from Terraform GitHub \nActions workflow can be used in Terraform configuration files. First, you need to define \nthem in variables.tf  for your project. See the sample code snippet below:  \nvariable \"deploy_repo\"  { \n  description = \"application's repo name\"  \n  type    = string \n  default = \"myrepo\"  \n} \n \nvariable \"deploy_env\"  { \n  description = \"deployment environment\"  \n  type    = string \n  default = \"dev\" \n} \n \nvariable \"pipeline_token\"  { \n  description = \"pipeline token\"  \n  type    = string \n  default = \"\" \n} \nWhen those Terraform environment variables are used in Terraform configuration files, \nsuch as  main.tf , you can refer to those Terraform environment variables as normal \nvariables in the form of  var.pipeline_token  (line 2),  var.deploy_repo  (line 9), \nand var.deploy_env  (line 10).  ", "doc_id": "73796437-2f75-4451-be44-7d2167a658e2", "embedding": null, "doc_hash": "e4ef028d8e2167dcfec423961255d31097da7445586d0e929063efce9eb27ab9", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 1271}, "relationships": {"1": "1d55e6a8-85da-4ee3-8835-cb6237151041"}}, "__type__": "1"}, "b64181ca-cf8c-4f47-b773-3c34b8df313d": {"__data__": {"text": "Step 3: Verify GitHub Secrets in the Application Pipeline  \nOnce your secrets are automated through the above step, you may want to verify whether \nthe secret is created with the right value. As you may already know, Gi tHub secrets UI \ndoesn\u2019t allow users to view the value of a secret once it\u2019s configured. If you need to verify \nthe value of the secret, you can use the snippet below in your application CI or CD \nworkflow, which uses  sed, stream editor, a Unix command, to ec ho the secret value, with \nspace separating each letter in the secret value.  \n- name: Verify secrets  \n  run: | \n    echo ${{ secrets.S3_BUCKET_NAME } } | sed -e 's/\\(.\\)/\\1 /g' \nNote this is only for debugging and secrets that don\u2019t hold sensitive values. Once y ou \nfinish verifying the secrets, remove or comment on this step from your workflow.  \nThat\u2019s it! With GitHub secrets creation automation, we have accomplished true end -to-\nend pipeline integration between the infrastructure and application pipelines. Once the  \ninfrastructure is provisioned through the infrastructure pipeline, all secrets have already \nbeen automatically inserted into your GitHub repository, allowing the application \npipeline to kick off and execute smoothly without the manual intervention of mana ging \nthose secrets. This glue binds these two pipelines together, making it an end -to-end \nstate -of-the-art pipeline experience for the developers.  \nSummary  \nAutomating GitHub secrets from Terraform outputs helps the smooth transition between \nthe infrastructu re and application pipelines. This article dived into the details of ", "doc_id": "b64181ca-cf8c-4f47-b773-3c34b8df313d", "embedding": null, "doc_hash": "016dd8b53cf59693edcc1fc1a55824ac234e1822934ac07ef9d46982fe51b925", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 1603}, "relationships": {"1": "685b87a4-a63a-4f4a-afce-8d54bd12428b"}}, "__type__": "1"}, "a11333f7-0930-4696-9b4a-2cfd34a6b6e9": {"__data__": {"text": "capturing Terraform outputs within Terraform GitHub Actions workflow and how to \nautomate GitHub secrets creation/update using GitHub provider in Terraform \nconfiguration. We also looked at  verifying if the secrets are created/updated as desired.  \nI hope you find this article helpful.  \nI welcome you to check out the rest of the four parts in my five -part \u201cThe Path to DevOps \nSelf-Service\u201d series:  \n \nDevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \nA high -level architectural overview of the self -service pipeline  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Terraform Project Structure  \nHow to structure Terraform code and its reusable modules  \nbetterprogrammi ng.pub  \n \n \nDevOps Self -Service -Centric GitHub Actions\u2019 Workflow Orchestration  \nHow to orchestrate GitHub Actions\u2019 workflow s that are driven by image immutability  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Security and Guardrails  \nA list of hand -picked actions for security scans and guardrails for your pipelines, \ninfrastructure, source code, base\u2026  \nbetterprogramming.pub  \n \nHappy coding!  \nReferences  \nhttps://registry.terraform.io/providers/integrations/github/latest/docs  ", "doc_id": "a11333f7-0930-4696-9b4a-2cfd34a6b6e9", "embedding": null, "doc_hash": "a97ef4b13ac6e1270924874d5c46f8cc631f34c904097ac4b9f366ff2197e979", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1217}, "relationships": {"1": "8ad38b29-a0b4-4396-883f-cd7dbb4ff242"}}, "__type__": "1"}, "875ff207-302a-4779-867e-c447d8c89d8f": {"__data__": {"text": "https://github.com/cloudposse/terraform -aws-cloudfront -s3-cdn \nhttps://registry.terraform.io/providers/integrations/github/latest/docs/resources/actio\nns_environment_secret  \n ", "doc_id": "875ff207-302a-4779-867e-c447d8c89d8f", "embedding": null, "doc_hash": "219703d31430f1a9973f6c7c26a12aa797f5958f4017989dabe05b30f3c9c164", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 178}, "relationships": {"1": "4581b228-3f4f-469d-b99a-9ae855107933"}}, "__type__": "1"}, "0691a233-b99c-435e-a986-dee90b3e4e27": {"__data__": {"text": "DevOps Self -Service Centric Pipeline Security and Guardrails  \nA list of hand -picked actions for security scans and guardrails for your pipelines, \ninfrastructure, source code, base images, and dependent libraries  \n \nDiagram by author  \n \nOur journey towards DevOps self -service has reached a few good milestones so far. We first \nexplored  DevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule , then we dived \ninto DevOps Self -Service Centric Terraform Project Structure , and in our last article, we talked \nabout  DevOps Self -Service Centric GitHub Actions Workflow Orchestration . \nComing from a traditional DevOps mindset, you may still be a bit skeptical. What about \nsecurity measures and guardrails for such DevOps self -service? Security is at the \n", "doc_id": "0691a233-b99c-435e-a986-dee90b3e4e27", "embedding": null, "doc_hash": "15be8ac9c19ffab1278dfba57e21edc1788a02b9e5ebe7c58d01df4093faa02d", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 774}, "relationships": {"1": "3cc7b2c6-65c8-4f24-b05e-161ad615bc76"}}, "__type__": "1"}, "6277cc64-14a2-44b0-b6d9-a674c31b4e2f": {"__data__": {"text": "foref ront of everyone\u2019s mind nowadays. Designing and implementing your pipelines to \nensure sound security is paramount.  \nDevOps self -service calls for relinquishing control to the developers. How can we have \npeace of mind when handing DevOps pipeline ownership t o developers? Great question \nyou asked. We hear you loud and clear! Security and guardrails are key implementation \npieces on this path to DevOps self -service. In this article, let\u2019s focus on pipeline security \nand guardrails, and you will see why you can ha ve peace of mind when rolling out your \nDevOps self -service practice.  \nFirst, let\u2019s briefly revisit our pipeline architecture. Notice the part highlighted in red \nbelow: This is the repository where your reusable Terraform modules and GitHub \nActions workflows  reside. Here, you\u2019ll need to implement your pipeline security and \nguardrails. This repository hosting your reusable workflows and modules acts like the \nengine of your DevOps self -service vehicle. With these security and guardrail measures \nimplemented in t his centralized repository, you have a higher quality engine, which helps \nguarantee a smoother ride.  \n \nDiagram by author  \n", "doc_id": "6277cc64-14a2-44b0-b6d9-a674c31b4e2f", "embedding": null, "doc_hash": "c086f26dacc50f9336a88878944e23c3af6cb9ab6868891d5183a39bd2ae1988", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 1179}, "relationships": {"1": "f2a52cd5-3355-4e8e-8b4b-0c00511168bd"}}, "__type__": "1"}, "995ae667-ff68-49a9-a0d1-871fba7339d3": {"__data__": {"text": "Developers, when implementing their pipeline logic in the caller workflows from their \napplications, do not need to know about the details of the security and guardrail \nmeasures. They are the consumers of the finished product of your high -quality reusable \nworkflows and modules, and they automatically catch any security or guardrail issues \ndevelopers introduce.  \nThe following list of tools, highlighted in red in the diagrams of the sample infrastructure \npipeline and sample application pipelin es below, have been hand -picked to improve the \nsecurity posture of your overall platform:  \n\u2022 your pipelines  \n\u2022 your infrastructure  \n\u2022 your source code  \n\u2022 your base images  \n\u2022 your dependent libraries  \n \nSample infrastructure pipeline. Diagram by author  \n", "doc_id": "995ae667-ff68-49a9-a0d1-871fba7339d3", "embedding": null, "doc_hash": "d257adc678f4d1fc170f95def19f18fc118e93631544a7a3473dd7ff69234d81", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 765}, "relationships": {"1": "cd9a62c9-a498-4b1e-90bb-a09fe694d186"}}, "__type__": "1"}, "95759b02-6e6e-4fdc-9a35-d68ec490182a": {"__data__": {"text": " \nSample application pipeline (CI workflow). Diagram by author  \n \nSample application pipeline (CD workflow). Diagram by author  \nLet\u2019s dive in and take a closer look at each highlighted action.  \nHarden -Runner  \nHarden -Runner  is the only action used in all pipelines \u2014 infrastructure and application \npipelines for CI and CD. Why? Because of the unique nature and purpose of Harden -\nRunner.  \n", "doc_id": "95759b02-6e6e-4fdc-9a35-d68ec490182a", "embedding": null, "doc_hash": "5dc6dcb3d9f38847c4e2f27e4f80de019aee85a80f33074e28ae7ee461368a92", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 398}, "relationships": {"1": "bd233b25-58e1-4100-957b-2aceb6d31439"}}, "__type__": "1"}, "ae756392-93c1-44b5-9773-c032fa736c52": {"__data__": {"text": "Deve loped by  StepSecurity , Harden -Runner is a purpose -built security monitoring agent \nfor your pipelines to detect and prevent malicious patterns observed during past software \nsupply chain security breac hes. The main features of Harden -Runner include:  \n\u2022 Automatically discovers and correlates outbound traffic with each step in your \npipeline, as compromised dependencies and build tools typically make \noutbound calls.  \n\u2022 Prevent exfiltration of credentials in the pipeline.  \n\u2022 Detect tampering of source code during the build.  \n\u2022 Detect compromised dependencies and build tools.  \nHarden -Runner is configured with two steps. First, you must enable its  audit  mode. \nHere\u2019s how to do that:  \n- name: Harden Runner \n  uses: step-security/harden -\nrunner@ebacdc22ef6c2cfb85ee5ded8f2e640f4c776dd5  \n  with: \n    egress-policy: audit # TODO: change to 'egress -policy: block' \nafter couple of runs  \nAfter running a couple of workflow runs, you can enable its  block  mode by whitelisting \nthe o utbound endpoints for all the actions called in your workflow. You can also \nconfigure notifications to be sent out via email or Slack if outbound endpoints that are \nnot in the  allowed-endpoints  list are called. The sample snippet below will help you \nsee ho w this works:  ", "doc_id": "ae756392-93c1-44b5-9773-c032fa736c52", "embedding": null, "doc_hash": "958592970d1384e5af1246804ebfa6276fda8a1868d34f61203ea328a6d2fdc4", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 1286}, "relationships": {"1": "3385ad0b-4bf0-4930-809b-4d5d52134971"}}, "__type__": "1"}, "a0a73669-5a48-49d7-a9a5-d25b35803954": {"__data__": {"text": "- name: Harden Runner \n  uses: step-security/harden -\nrunner@ebacdc22ef6c2cfb85ee5ded8f2e640f4c776dd5  \n  with: \n    disable-sudo: true \n    egress-policy: block \n    allowed-endpoints:  > \n      api.adoptopenjdk.net:443  \n      api.ecr.us -east-1.amazonaws.com:443  \n      apk.corretto.aws:443  \n      dl-cdn.alpinelinux.org:443  \n      ghcr.io:443  \n      github.com:443  \n      objects.githubusercontent.com:443  \nAlso, note the line  disable-sudo: true  in the above snippet.  Sudo  allows the user  to \ndelegate privileges to run commands as a root or another user. This drastically increases \nthe risk because the root user can do anything to the system. Harden -Runner monitors \nroot usage in audit mode and makes these findings available on the  insights page . If \nHarden -Runner doesn\u2019t observe any  sudo  calls, you will see a recommendation to \nset disable-sudo  to true. It\u2019s a security best practice to disable  sudo  if you are not \nusing it.  \nWith Harden -Runner, you are confident this shield protects your pipeline well. It\u2019s fair to \nsay that Harden -Runner is your pipelines\u2019 security guard.  \nStepSecurity maintains great documentation on Harden -Runner. Step -by-step guidanc e \ncan be found at  https://docs.stepsecurity.io/ . Do check it out!  \nI wrote an article a few months ago on  A First Look at Harden Runner: the Must Have \nGitHub Action to Prevent Supply Chain Attacks . Feel free to check it out for more details.  ", "doc_id": "a0a73669-5a48-49d7-a9a5-d25b35803954", "embedding": null, "doc_hash": "0ce41f743359de59a6465d4e13e7e04ae958962eadffa7430ae8c4db8b2dccae", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 1449}, "relationships": {"1": "23508db5-40c0-4fec-9072-f424dedbf83d"}}, "__type__": "1"}, "89fc560d-cac6-4450-bd42-542faffb37bf": {"__data__": {"text": "Infracost  \nSo oft en, spikes in cloud cost get captured after you have incurred the cost.  Infracost  lets \nDevOps, SRE, and engineers see a cost breakdown and understand costs before making \nchanges in the terminal or pull requests. This provides your team with a safety net to \ncatch abnormal cloud cost estimates due to fat fingering or misconfiguration in \nTerraform configuration.  \nSee the following screenshot of a sample pull request (PR) comment added by Infracost \nwhen you c reate a new PR with Terraform code changes for your application. The diff \namount between the previous cost and the new cost based on the latest Terraform code \nchanges is $0.83. Small as it may be, the diff feature enables you to validate your \nTerraform cod e changes against a predefined diff threshold. Your workflow will fail if the \ndiff amount exceeds the predefined threshold amount. This indeed serves as the \nguardrail for your cloud cost management while opening up the infrastructure code \ncontrol to the de velopers.  ", "doc_id": "89fc560d-cac6-4450-bd42-542faffb37bf", "embedding": null, "doc_hash": "f3c9a57b15b08a0086fc05b066b7516917d5c8c114bbb7ab2571e9bc974990b1", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 1018}, "relationships": {"1": "1e570c30-dd39-4ce0-b593-b2370846a169"}}, "__type__": "1"}, "59d97930-3f0f-40e5-9002-5a4959c59353": {"__data__": {"text": " \nThe next screenshot shows a sample email of a customized Infracost workflow that can \nnotify you of you r application\u2019s monthly costs. These costs are based on your static \nTerraform configuration and the dynamic usage configuration for your cloud resources.  \n", "doc_id": "59d97930-3f0f-40e5-9002-5a4959c59353", "embedding": null, "doc_hash": "b9993422268fc6f621dd405d6884bf8232491c314eb13931aaa96fe3e79992b9", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 263}, "relationships": {"1": "7fe31f27-ffe0-4454-ab01-ee87fc3a690a"}}, "__type__": "1"}, "49a55a9b-b979-4bc1-8979-2569955f2572": {"__data__": {"text": " \nHere are some of the key steps you can include in your infracost GitHub Actions \nworkflow, notice the comments above each step, which walk you throug h how you arrive \nat the diff amount on your infrastructure cost based on your base branch and your PR \nbranch, and a report can be generated, also a comment can be added to your PR to \nindicate the diff details, as seen in the screenshot above.  \n    # this st ep calls infracost/actions/setup@v2, which installs \nthe latest patch version of the Infracost CLI v0.10.x and  \n    # gets the backward -compatible bug fixes and new resources. \nReplacing the version number with git SHA is a security hardening \nmeasure.  \n    - name: Setup Infracost  \n      uses: \ninfracost/actions/setup@6bdd3cb01a306596e8a614e62af7a9c0a133bc5c  \n      with: \n        api-key: ${{ secrets.INFRACOST_API_KEY } } \n \n    # Checkout the base branch of the pull request (e.g. main).  \n    - name: Checkout base branc h \n      uses: \nactions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8  \n      with: \n", "doc_id": "49a55a9b-b979-4bc1-8979-2569955f2572", "embedding": null, "doc_hash": "766df0585e4543b3482334f78f453331f057e3771a7a259863a27c0c9fccb9ab", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1035}, "relationships": {"1": "9920c8c9-c70d-4cb5-a982-da0849dd3518"}}, "__type__": "1"}, "5b96d7e4-f706-4eff-9c2f-5e607c792260": {"__data__": {"text": "        ref: '${{ github.event.pull_request.base.ref }}'  \n \n    # Generate Infracost JSON file as the baseline.  \n    - name: Generate Infracost cost estimate baseline  \n      run: | \n        export INFRACOST_API_KEY= ${{ secrets.INFRACOST_API_KEY } } \n        cd ${TF_ROOT}  \n        infracost breakdown --path=. \\ \n                            --terraform -var-file=${{ \ninputs.terraform -var-file }} \\ \n                            --usage-file ${{ inputs.usage -file }} \\ \n                            --format=json \\ \n                            --out-file=/tmp/infracost -base.json  \n \n    # Checkout the current PR branch so we can create a diff.  \n    - name: Checkout PR branch  \n      uses: \nactions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8  \n \n    # Generate an Infracost diff and save it to a JSON file.  \n    - name: Generate Infracost diff  \n      run: | \n        export INFRACOST_API_KEY= ${{ secrets.INFRACOST_API_KEY } } \n        cd ${TF_ROOT}  \n        infracost diff --path=. \\ \n                        --format=json \\ \n                        --show-skipped \\ \n                        --terraform -var-file=${{ inputs.terraform -\nvar-file }} \\ \n                        --usage-file ${{ inputs.usage -file }} \\ \n                        --compare-to=/tmp/infracost -base.json \\ \n                        --out-file=/tmp/infracost.json  \n \n    # generate the html report based on the JSON output from last \nstep \n    - name: Generate Infracost Report  \n      run: | \n        export INFRACOST_API_KEY= ${{ secrets.INFRACOST_API_KEY } } \n        cd ${TF_ROOT}  \n        infracost output --path /tmp/infracost.json --show-skipped \n--format html --out-file report.html  \n \n    # upload the report to artifact so subsequent workflow can \ndownload the report and email it as attachment  \n    - uses: actions/upload -\nartifact@0b7f8abb1508181956e8e162db84b466c27e18ce # v3.1.2  \n      with: ", "doc_id": "5b96d7e4-f706-4eff-9c2f-5e607c792260", "embedding": null, "doc_hash": "b03988abc5ed24b15b2be62262d8e97c9656b1ecf9c3aca7aec41b95a8b01bcf", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 1907}, "relationships": {"1": "ebb7bd7c-7c8b-400e-aa05-9c5621782ecf"}}, "__type__": "1"}, "863be920-cf77-42cb-8a7d-e5ece91ca410": {"__data__": {"text": "        name: report.html  \n        path: ${{ inputs.w orking-directory } }/report.html  \n \n    # Posts a comment to the PR using the 'update' behavior.  \n    # This creates a single comment and updates it. The \"quietest\" \noption. \n    # The other valid behaviors are:  \n    #   delete -and-new - Delete previous comments and create a new \none. \n    #   hide -and-new - Minimize previous comments and create a new \none. \n    #   new - Create a new cost estimate comment on every push.  \n    #   update - Update a cost estimate comment when there is a \nchange in the cost estimate.  \n    # See \nhttps://www.infracost.io/docs/features/cli_commands/#comment -on-\npull-requests for other options.  \n    - name: Post Infracost comment  \n      run: | \n        export INFRACOST_API_KEY= ${{ secrets.INFRACOST_API_KEY } } \n        infracost comment github --path=/tmp/infracost.json \\ \n                                 --repo=$GITHUB_REPOSITORY  \\ \n                                 --github-token=${{github.token} } \\ \n                                 --pull-\nrequest= ${{github.event.pull_request.number} } \\ \n                                 --behavior=update \\ \n                                 --policy-\npath=${TF_ROOT} /infracost -policy.rego  \nInfracost is a must -have tool in rolling out your DevOps self -service practice. In addition \nto the open -source version, which can be integra ted into your infrastructure pipeline, \nInfracost offers a paid cloud version with many cool features. Some of these perks are a \ncentralized dashboard, which gives you a glance at all your PRs and the cost changes they \nintroduce, integration into issue trac kers such as JIRA, guardrails that help you control \ncosts by monitoring PRs, and the ability to trigger actions when your defined thresholds \nare exceeded.  ", "doc_id": "863be920-cf77-42cb-8a7d-e5ece91ca410", "embedding": null, "doc_hash": "9eb769c013b6f4a7e31256ba04445bd5f316a3199b0982b5bdf7bedcb66d9c16", "extra_info": {"page_label": "11"}, "node_info": {"start": 0, "end": 1805}, "relationships": {"1": "d6adebef-c6eb-43e5-a41b-705aa73f039f"}}, "__type__": "1"}, "be68e1eb-7944-4469-a31d-0d31dd1752a6": {"__data__": {"text": "One recently introduced feature in Infracost Cloud is its centralized cost policies. These \nlet you de fine central policies and scan your repositories for cost -saving opportunities. \nHow cool is that! For more details, refer to  Centralized cost policies | Infracost . \nInfracost maintains excellent documentation and detailed instructions to get you started. \nYou can find out more at  https://www.infracost.io/docs/ . Infracost i s indeed a rare gem \nin the open source space. Definitely add it to your toolkit for your DevOps self -service.  \nI wrote an article with step -by-step instructions on integrating Infracost into your \nTerraform workflow a few months ago. Feel free to check it ou t: Infracost + Terraform + \nGitHub Actions = Automate Cloud Cost Management . \nTFLint  \nTFLint  is a framework, and each feature is provided by plugins. The key features are as \nfollows:  \n\u2022 Find possible errors (like invalid instance types).  \n\u2022 Warn about deprecated syntax  and unused declarations.  \n\u2022 Enforce best practices and naming conventions.  \nIncorporate TFLint in Terraform GitHub Actions workflow for your project to automate \nlinting during Terraform workflow execution. See some sample actions/steps for TFLint \nin an infras tructure pipeline in the example below:  \n- uses: actions/cache@937d24475381cd9c75ae6db12cb4e79714b926ed  # \nv2.1.7 ", "doc_id": "be68e1eb-7944-4469-a31d-0d31dd1752a6", "embedding": null, "doc_hash": "9b2b54fb88b8bc62f1f9bd9e6e35d72260209be022092e46099fee6e9e7f3006", "extra_info": {"page_label": "12"}, "node_info": {"start": 0, "end": 1354}, "relationships": {"1": "0d24d8be-692c-4f63-b249-0e5ad54d4d36"}}, "__type__": "1"}, "de2c4b25-b6c7-4657-b1c1-e650f4777643": {"__data__": {"text": "  name: Cache plugin dir \n  with: \n    path: ~/.tflint.d/plugins  \n    key: ubuntu-latest-tflint-${{ hashFiles('.tflint.hcl')  }} \n \n- uses: terraform -linters/setup -\ntflint@444635365d380c7363d1eaee4267317c2445717d  # v2.0.1  \n  name: Setup TFLint \n  with: \n    tflint_version:  latest \n \n- name: Init TFLint \n  run: tflint --init \n \n- name: Run TFLint \n  run: tflint -f compact \nAlso, here\u2019s a screenshot of a sample TFLint error captured from the Terraform GitHub \nActions workflow. As you can see, there are warning points for the variable  s3_bucket , \nwhich is declared but not used. TFLint really helps keep your code clean an d concise. \nWith standards and best practices enforced by frameworks/tools like TFLint, DevOps \nself-service can be a breeze!  \n \nCheckov  \nCheckov is a static code analysis tool for infrastructure as code (IaC) and software \ncomposition analysis (SCA) for images and open source packages. With  over 1,000 built -\nin policies  covering security and compliance best practices for all major cloud providers, \n", "doc_id": "de2c4b25-b6c7-4657-b1c1-e650f4777643", "embedding": null, "doc_hash": "4a876c4f6e5f9f0bc7d8f2ccda1fc63e946189e7960fb9b486c4ae0c07246eb1", "extra_info": {"page_label": "13"}, "node_info": {"start": 0, "end": 1042}, "relationships": {"1": "b0f4050a-7ffb-4c63-a758-ff58ebbf9917"}}, "__type__": "1"}, "0790e3d6-c697-4f3e-8ced-fbe9cea7dd7d": {"__data__": {"text": "Checkov scans Terraform, Terraform Plan, CloudFormation, AWS SAM, Kubernetes, \nDockerfile, Serverless framework, Bicep, and ARM template files. It also supports in -\nline suppression  of accepted risks or false positives to reduce recurring scan failures.  \nThe followin g step for Checkov action can be incorporated into your Terraform GitHub \nActions workflow:  \n- name: Run Checkov action \n  uses: bridgecrewio/checkov -\naction@3854b91536303a096e7693434ef98706a0be82cb  # master  \n  with: \n    directory:  ${{ inputs.working -directory  }} \n    quiet: true # optional: display only failed checks  \n    soft_fail:  true # optional: do not return an error code if \nthere are failed checks  \n    framework:  terraform  # optional: run only on a specific \ninfrastructure {cloudformation,terraform,kubernetes,all}  \n    output_format:  sarif # optional: the output format, one of: \ncli, json, junitxml, github_failed_only, or sarif. Defau lt: sarif  \n    output_file_path:  reports/results.sarif  # folder and name of \nresults file  \n    download_external_modules:  true # optional: download external \nterraform modules from public git repositories and terraform \nregistry  \n    log_level:  DEBUG # optional: set log level. Default WARNING  \nHere\u2019s a sample failed check of Checkov. It includes the description of the point, file \nname , line numbers, and remediation guide documentation links:  ", "doc_id": "0790e3d6-c697-4f3e-8ced-fbe9cea7dd7d", "embedding": null, "doc_hash": "38fa514534f2f4d341017f37b0bce1eed487d19ab43db463c1dc44344841d897", "extra_info": {"page_label": "14"}, "node_info": {"start": 0, "end": 1394}, "relationships": {"1": "4962a225-fcfa-49d3-9057-1971b9c80a8e"}}, "__type__": "1"}, "0b047e10-456c-494a-a18c-4c63011c4c55": {"__data__": {"text": " \nMore information on Checkov can be found on its GitH ub \nrepository  https://github.com/bridgecrewio/checkov . \nTFSec  \nRecommended by  ThoughtWorks , TFSec  uses static analysis of the Terraform code to \nspot potential misconfigurations. Here are the main features of TFSec:  \n\u2022 Checks for misconfigurations across all major (and some minor) cloud \nproviders  \n\u2022 Hundreds of built -in rules  \n\u2022 Evaluates HCL expressions as well as literal values  \n\u2022 Evaluates Terraform functions, e.g.,  concat()  \n\u2022 Evaluates relationships between Terraform resources  \n", "doc_id": "0b047e10-456c-494a-a18c-4c63011c4c55", "embedding": null, "doc_hash": "5fa2dc72b2b9593066394be7e4f73e959d6a0c4edf697906660af7672a68c43f", "extra_info": {"page_label": "15"}, "node_info": {"start": 0, "end": 559}, "relationships": {"1": "b058a491-3b2f-455f-bcca-eb8c4fdec613"}}, "__type__": "1"}, "e8eb1674-1c19-4323-800f-5e7552dc34d3": {"__data__": {"text": "\u2022 Applies (and embellishes) user -defined Rego policies  \n\u2022 Supports multiple output formats: lovely (default), JSON, SARIF, CSV, \nCheckStyle, JUnit, text, Gif.  \n\u2022 Very fast. Capable of quickly scanning huge repositories  \nHere\u2019s a sample result point. It highlights the severity of the issue, the description, the \nfile, the line number, and the links to more information about why TFSec flagged that \nline as a security issue. See more below:  \nResult #1 CRITICAL Listener uses an outdated TLS policy.  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n  github.com \\###\\###\\terraform \\modules\\ecs\\cluster_alb \\main.tf:105  \n   via main. tf:64-83 (module.cluster_alb)  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n  100    resource \"aws_alb_listener\"  \"https\" { \n  ...   \n  105  [   ssl_policy        = \"ELBSecurityPolicy -2016-08\" \n(\"ELBSecurityPolicy -2016-08\") \n  ...   \n  112    } \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n          ID aws-elb-use-secure-tls-policy \n      Impact The SSL policy is outdated and has known \nvulnerabilities  \n  Resolution Use a more recent TLS/SSL policy for the load b alancer \n \n  More Information  \n  - \nhttps://aquasecurity.github.io/tfsec/v1.22.1/checks/aws/elb/use -\nsecure-tls-policy/ \n  - \nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/r\nesources/lb _listener  ", "doc_id": "e8eb1674-1c19-4323-800f-5e7552dc34d3", "embedding": null, "doc_hash": "a2e2066530835620ed4137c3fc4ac83e795354e5c6ab4a02e7fd54816f0c72e6", "extra_info": {"page_label": "16"}, "node_info": {"start": 0, "end": 1445}, "relationships": {"1": "6d4f2826-f04e-4ab3-9bb8-ffe09dee2cf1"}}, "__type__": "1"}, "884c7614-8e49-475e-a3c8-e517b360e118": {"__data__": {"text": "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nTFSec can be incorporated into your Terraform GitHub Actions workflow, so when you \nprovision infrastructure for your app, TFSec will start by doing a static Terraform code \nanalysis to detect potential security risks. The TFSec step in Terraform GitHub Actions \nworkflow looks like this:  \n- name: Run tfsec, static analysis  tool to detect potential  \nsecurity  risks \n  uses: aquasecurity/tfsec -pr-commenter -\naction@7a44c5dcde5dfab737363e3 91800629e27b6376b  # v1.3.1  \n  with: \n    tfsec_args:  --soft-fail \n    github_token:  ${{ github.token  }} \n--soft-fail  is a flag to tell your GitHub Actions workflow to not fail the workflow if \nsecurity risks are found. This should be used cautiously and only when multiple \ndevelopers are working on the same application, but doing different tasks. Some may be \nlooking into t he vulnerability fix, while others actively work on feature development. \nIntroducing the  --soft-fail  flag allows the developers to continue developing new \nfeatures while the other developer(s) can work on fixing the vulnerabilities found.  \nThere is a known issue with TFSec not working well with pinned Terraform reusable \nmodules. I opened  this issue  in November 2022. The TFSec team is still working on the \nfix as of this writing. I a m looking forward to the fix.  ", "doc_id": "884c7614-8e49-475e-a3c8-e517b360e118", "embedding": null, "doc_hash": "25ff09b0e23d47cafc718f75ac374ad66284b92747cca17c97b54759f9ea5fe1", "extra_info": {"page_label": "17"}, "node_info": {"start": 0, "end": 1388}, "relationships": {"1": "83129db1-45fd-4021-9b44-97fefac46450"}}, "__type__": "1"}, "13c430e0-562d-4bf2-99d6-43a4e8363188": {"__data__": {"text": "For more details on this action, refer to  https://github.com/aquasecurity/tfsec -pr-\ncommenter -action . \nTrivy  \nTrivy is a comprehensive and vers atile open source security scanner. It is designed to be \nfast and easy to use, and it can be run from the command line or integrated into a CI/CD \nworkflow. The snippet below shows the Trivy scan step in a GitHub Actions CI workflow:  \n- name: Scan docker image with Trivy vulnerability  scanner \n  uses: aquasecurity/trivy -\naction@9ab158e8597f3b310480b9a69402b419bc03dbd5  \n  with: \n    image-ref: ${{ steps.build -image.outputs.image  }} \n    format: 'table' \n    exit-code: '1' \n    ignore-unfixed:  true \n    vuln-type: 'os,library'  \n    severity:  'CRITICAL,HIGH'  \nTrivy scans container images for known vulnerabilities in the operating system packages \nand libraries that they use. It uses a database of vulnerability information provided by \nthe National Vulnerabilit y Database (NVD) and other sources.  \nWhat Trivy can scan  \n\u2022 Container Image  \n\u2022 File system  \n\u2022 Git Repository (remote)  \n\u2022 Virtual Machine Image  ", "doc_id": "13c430e0-562d-4bf2-99d6-43a4e8363188", "embedding": null, "doc_hash": "b169b298d34447df8c420e076dd1e99574eb7a8ce625a761ec9164aaab0e288c", "extra_info": {"page_label": "18"}, "node_info": {"start": 0, "end": 1077}, "relationships": {"1": "10f4f69a-6a9b-4bff-8f0a-e1085758fe55"}}, "__type__": "1"}, "a6ffabd5-6683-4291-9417-5573858c75be": {"__data__": {"text": "\u2022 Kubernetes  \n\u2022 AWS  \nWhat Trivy can find  \n\u2022 OS packages and software dependencies in use (SBOM)  \n\u2022 Known vulnerabilities (CVEs)  \n\u2022 IaC issues and misconfigurations  \n\u2022 Sensitive information and secrets  \n\u2022 Software licenses  \nSee the following screenshot of a sample Trivy scan result in the application CI workflow.  \nThe error indicates there is a vulnerability in the base image.  \n \nYou will need to provide a fix to update the vulnerable packages to the latest versions in \nthe base image in you r Dockerfile , especially under the following conditions:  \n", "doc_id": "a6ffabd5-6683-4291-9417-5573858c75be", "embedding": null, "doc_hash": "108b7a9cfe815f2d7e73e3dfd6ef519e27c4c5335a1610d481f5379c011e9426", "extra_info": {"page_label": "19"}, "node_info": {"start": 0, "end": 566}, "relationships": {"1": "08385f70-454d-45b0-9171-af64e87c6951"}}, "__type__": "1"}, "12afc639-c882-4f6e-9018-24fff185be63": {"__data__": {"text": "\u2022 If your app uses an alpine base image, add the line  RUN apk update && \napk upgrade -U -a under the  FROM <base image>  line in \nyour  Dockerfile . For example:  \nFROM amazoncorretto:17 -alpine-jdk \nRUN apk upd ate && apk upgrade -U -a \n... \n\u2022 If your app doesn\u2019t use alpine base image, you can add the line  RUN apt-get \nupdate && apt -get upgrade -y under the  FROM <base image>  line \nin your  Dockerfile . For example:  \nFROM openjdk: 17.0.2-jdk-slim-bullseye  \nRUN apt-get update && apt-get upgrade -y \n... \nWith the above fix, your CI should be able to pass the base image scan.  \nFor those who have been using Trivy in your pipeline, you may have noticed the recent \nTrivy timeout error: \" FATAL image scan error: scan error: scan fa iled: \nfailed analysis: analyze error: timeout: context deadline \nexceeded \". Per this  issue  in Trivy\u2019s GitHub repo issues, the root cause is \nwith  search.maven.org  timing out intermittently. As of 1/22/2023, it was reported \non this link  that the intermittent timeout errors from search.maven.org have been \nresolved, and they are investigating the root cause.  \nTruffleHog  ", "doc_id": "12afc639-c882-4f6e-9018-24fff185be63", "embedding": null, "doc_hash": "51877aac883219d7fe86eb4451774bae868c75f85625eaf784b136579697f9fd", "extra_info": {"page_label": "20"}, "node_info": {"start": 0, "end": 1124}, "relationships": {"1": "ac8aebe1-1c14-4e3b-9b69-1c58c5ca2a83"}}, "__type__": "1"}, "269146dd-5b52-425a-b846-c8323bbb01d4": {"__data__": {"text": "TruffleHog is a tool that searches through Git repositories for high entropy strings, such \nas passwords and API keys. It can help identify and prevent data leaks by detecting \nsecrets accidentally committed to a repository. It works by calculating the entro py of a \nstring, which measures the amount of randomness or complexity in the string. Strings \nwith high entropy are more likely to be secrets, and TruffleHog searches through a \nrepository\u2019s commit history looking for these high -entropy strings.  \nTruffleHog, incorporated into your application\u2019s CI workflow, can auto -detect secrets \nleak during CI build. Here\u2019s how to get started:  \n- name: TruffleHog  Secrets Scan \n  uses: trufflesecurity/trufflehog@main  \n  with: \n    path: ./ \n    base: ${{ github.event.repository.de fault_branch  }} \n    head: HEAD \n    extra_args:  --debug --only-verified  \nThe --only-verified  flag in the  extra_args  input parameter scans verified secrets, \nwhich means live secrets can be used to log into your provider service or application. \nThese may be yo ur cloud provider, RDS, or any other services/applications your secrets \nare used for authentication. These live secrets, once leaked into the hands of bad actors, \nare bound to cause damage to your platform. So be sure to include TruffleHog in your \npipeline s. Be the police of your own application.  \nFor more details on TruffleHog, refer to its GitHub \nrepository  https://github.com/trufflesecurity/trufflehog . \nSonarScan  ", "doc_id": "269146dd-5b52-425a-b846-c8323bbb01d4", "embedding": null, "doc_hash": "67164d6c1994201e98146acc88e152dc3249daeb449027022b5f0e00bb09084a", "extra_info": {"page_label": "21"}, "node_info": {"start": 0, "end": 1485}, "relationships": {"1": "7ab48f9b-296b-40e4-a82f-6116166d21d1"}}, "__type__": "1"}, "8a291e38-f5fb-41f8-a1e6-71fcc12c7bfa": {"__data__": {"text": "SonarScan is a code -scanning tool that analyzes source code for security vulnerabilities, \ncode smells, and other issues. It is typically used in software development to help \nimprove the quality and s ecurity of code. SonarScan can be run on various programming \nlanguages and integrates with GitHub Actions.  \nIn addition to security vulnerabilities and code smells, SonarScan can also be configured \nto check for compliance with coding standards and best prac tices and to detect \nduplication and other problems in the codebase.  \nTo add SonarScan to your GitHub Actions CI workflow, add the following action:  \n- name: SonarQube  Scan \n  uses: sonarsource/sonarqube -scan-action@master  \n  env: \n    SONAR_TOKEN:  ${{ secrets.SONAR_TOKEN  }} \n    SONAR_HOST_URL:  ${{ secrets.SONAR_HOST_URL  }} \nRefer to  https://github.com/Sonar Source/sonarqube -scan -action  for more details on the \nusage variations of this action.  \nNotice we have Trivy scan, Trufflehog scan, and SonarScan triggered after the Docker \nimage has been pushed to the container registry, such as ECR, in the application CI \nworkflow. The design intention behind it is similar to the  --soft-fail  flag in the \nTFSe c section. This allows multiple developers to work on the same application without \nbeing blocked for security vulnerability issues as other developer(s) work on the \nvulnerability fix. This is a mere recommendation. You can adjust the sequence of those \nsecu rity actions and guardrails based on your pipeline needs.  ", "doc_id": "8a291e38-f5fb-41f8-a1e6-71fcc12c7bfa", "embedding": null, "doc_hash": "f9e6388651bd0c5522b473dcd6db0885be2329904fdd1d915fb4724e6b676667", "extra_info": {"page_label": "22"}, "node_info": {"start": 0, "end": 1509}, "relationships": {"1": "6c7b18c9-3faf-4afd-95a5-e8f007f574c5"}}, "__type__": "1"}, "465a28a3-c8ab-46cb-93b4-00bb84938f75": {"__data__": {"text": "Summary  \nOne major concern of DevOps self -service is how you ensure that pipeline security and \nguardrails are properly addressed and implemented. We looked closely at a list of hand -\npicked actions fo r pipeline security and guardrails for not only source code and \ndependent libraries, but also base image, infrastructure, and pipelines. These actions are \nimplemented in the GitHub Actions reusable workflows for infrastructure and \napplication pipelines to ensure they are adhered to by developers when developing caller \nworkflows for their applications. I hope you find this article helpful.  \nI welcome you to check out the rest of the four parts in my five -part \u201cThe Path to DevOps \nSelf-Service\u201d series:  \n \nDevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \nA high -level architectural overview of the self -service pipeline  \nbette rprogramming.pub  \n \n \nDevOps Self -Service Centric Terraform Project Structure  \nHow to structure Terraform code and its reusable modules  \nbetterprogrammi ng.pub  \n \n \nDevOps Self -Service -Centric GitHub Actions\u2019 Workflow Orchestration  \nHow to orchestrate GitHub Actions\u2019 workflow s that are driven by image immutability  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Integration  \nSecrets management as t he glue of pipeline integration  \nbetterprogramming.pub  \n \nHappy coding!  ", "doc_id": "465a28a3-c8ab-46cb-93b4-00bb84938f75", "embedding": null, "doc_hash": "432ffcd2bcfc24c7c81fb8e77390358099ca0ae354ba0fb814ac8399dd2fe945", "extra_info": {"page_label": "23"}, "node_info": {"start": 0, "end": 1367}, "relationships": {"1": "b7182f09-b4e1-4120-ad60-21f3c5477de7"}}, "__type__": "1"}, "f38c24f7-3e2b-4c3d-a808-16007525ac1e": {"__data__": {"text": "References  \n\u2022 https://github.com/step -security/harden -runner  \n\u2022 https://docs.stepsecurity.io/  \n\u2022 Disable Sudo | StepSecurity  \n\u2022 https://www.infracost.io/  \n\u2022 https://www.infracost.io/docs/infracost_cloud/cost_policies/  \n\u2022 aquasec urity/tfsec: Security scanner for your Terraform code (github.com)  \n\u2022 GitHub \u2014 bridgecrewio/checkov: Prevent cloud misconfigurations and find \nvulnerabilities during build -time in infrastructu re as code, container images \nand open source packages with Checkov by Bridgecrew  \n\u2022 https://github.com/aquasecurity/tfsec -pr-commenter -action  \n\u2022 https://github.com/aquasecurity/trivy  \n\u2022 https://github.com/trufflesecurity/trufflehog  \n\u2022 https://github.com/SonarSource/sonarqube -scan -action  \n ", "doc_id": "f38c24f7-3e2b-4c3d-a808-16007525ac1e", "embedding": null, "doc_hash": "84e5ad42f2c8bbefeaae2c3176c3502b24b6b5faac93885b4d93f1b7c09b798f", "extra_info": {"page_label": "24"}, "node_info": {"start": 0, "end": 732}, "relationships": {"1": "3506ae53-2e19-4e96-9a91-9b800526440a"}}, "__type__": "1"}, "104649c5-7beb-4e6f-808f-c6c6c70e9159": {"__data__": {"text": "DevOps Self -Service Centric Terraform Project Structure  \nHow to structure Terraform code and its reusable modules  \n \n \nPhoto by Craig Glantz  \n \nBefore we dive into Terraform project structure, I\u2019d like to share a fun fact to assure you \nwe are in the right boat with Terraform!  \nPer GitHub\u2019s  The State of the Octoverse survey of 2021 \u20132022 , the Hashicorp \nConfiguration Language (HCL) took first place in the fastest -growing programming \nlanguage category over the past year. Thi s was largely driven by the growth in the \n", "doc_id": "104649c5-7beb-4e6f-808f-c6c6c70e9159", "embedding": null, "doc_hash": "b44f8aedbbab26dce5fc6d6ace22924d63a98cbe8d124571e454ccb8f408905e", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 531}, "relationships": {"1": "f7c7ceb4-411c-4497-a477-a69ae4300b59"}}, "__type__": "1"}, "9a0a5cd3-bb90-4258-90f7-ab37035bb790": {"__data__": {"text": "popularity of the Terraform tool and IaC practices to automate deployments in the cloud \nincreasingly.  \n \nImage source:  The top programming languages | The State of the Octoverse \n(github.com)  \n", "doc_id": "9a0a5cd3-bb90-4258-90f7-ab37035bb790", "embedding": null, "doc_hash": "9ae55a6cedd253347c90246983970890837e94c0abeadceb4d529c932e52e053", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 197}, "relationships": {"1": "854373b4-2ed9-4bfd-aa04-29a6455c93d7"}}, "__type__": "1"}, "c6dda3e3-0a0e-4c47-a17d-506844ed5f1a": {"__data__": {"text": "Guided by the DevOps self -service pipeline architecture , we will explore how to structure \nTerrafor m code and its reusable modules in this story. Notice the red highlighted \nrectangle in the diagram below. Let\u2019s dive in.  \n \nDiagram by author  \nTerraform Reusable Modules  \nIn Terraform, a module is a container for multiple resources used together. Modules can \ncreate reusable components and are a good way to organize your infrastructure into \nlogical units. Benefits of reusable Terraform modules include:  \n\u2022 DRY (Don\u2019t Repeat Your self) Principle: Modules allow you to define your \ninfrastructure in a reusable way, reducing the amount of code duplication \nand making it easier to manage.  \n\u2022 Reusability: Modules can be used across multiple environments and \nprojects, allowing you to reuse yo ur infrastructure code.  \n\u2022 Organization: Modules help you to organize your infrastructure code into \nlogical units, making it easier to understand and maintain.  \n", "doc_id": "c6dda3e3-0a0e-4c47-a17d-506844ed5f1a", "embedding": null, "doc_hash": "ba6824e7716b9e49ce3d752844bab8c35eb5b4ae68ad3dee21e32406c63226c8", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 968}, "relationships": {"1": "38a891d3-a6f0-4b8b-a58a-715ecb821927"}}, "__type__": "1"}, "84a82939-8571-4f50-ab99-fb40bd13fe97": {"__data__": {"text": "\u2022 Collaboration: Modules can be shared with other teams and organizations, \nmaking it easier to collab orate on infrastructure projects.  \n\u2022 Standardization: Help standardize compliance and security standards \nacross various infrastructures and projects.  \nTerraform reusable modules should be kept in a centralized repository, which acts sort of \nlike a private Terr aform registry. For demo purposes, we can call this centralized \nrepo  reusable -workflows -modules . What does the reusable module structure look \nlike? See the sample screenshot below:  ", "doc_id": "84a82939-8571-4f50-ab99-fb40bd13fe97", "embedding": null, "doc_hash": "60911afebd4e8be9bb7f4dc1f43f50f02819f0467f4cb4409c8bebc3d5268c41", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 556}, "relationships": {"1": "fc3b4a27-eabb-4912-96bf-322c5d433c6c"}}, "__type__": "1"}, "e939d002-ce8c-476d-b93b-08d49e817222": {"__data__": {"text": " \nimage by author  \n", "doc_id": "e939d002-ce8c-476d-b93b-08d49e817222", "embedding": null, "doc_hash": "b6c190d2762d3d92e1fc25cd07cf4ede566abe964c8519544ce8ace3b628a2b4", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 20}, "relationships": {"1": "aab364b8-44ff-4650-8dcb-9d5641d7b68d"}}, "__type__": "1"}, "0fb22452-2cdc-48fc-b6f3-bf92d1069dfe": {"__data__": {"text": "Under the  terraform/modules  directory, you can have one or m ultiple reusable \nmodules. Notice each reusable module contains a list of files with standard naming \nconventions, which are pretty self -explanatory by their file names:  \n\u2022 main.tf  \n\u2022 outputs.tf  \n\u2022 variables.tf  \n\u2022 README.md  \nThis file structure is merely a recommendation. Depending on the complexity of your \nreusable module(s), you may need to include other files in your file structure.  \nProject -Specific Terraform Code  \nSince we use GitHub Actions as our CI/CD tool, it makes sense for us to have Terraform \ncode committed together with the project source code in the same repository. Suppose \nwe have all Terraform code for all our projects committed in one standalone repo.  \nIn that case, we cannot run GitHub Actions workflows to deploy Terraform to different \nenvironments/accounts in AWS for different projects, as it becomes extremely \nchallenging for us to manage GitHub Environments/secrets and to match IAM \ncredentials for many projects within the same repo.  \nIt is best for Terraform code to reside in the same repo as its project source code. See the \nsample screenshot below, where in this project,  springboot -infracost -demo , \nTerraform code is located under a  terraform  directory und er root. There is a matching ", "doc_id": "0fb22452-2cdc-48fc-b6f3-bf92d1069dfe", "embedding": null, "doc_hash": "6c8083b2660fc8d4d32b0a4bd6439a7de02498b2ca8e0b684f9ea40fcdeeb6c9", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 1311}, "relationships": {"1": "5d78f080-10bc-4458-8f5c-850f04ffdfeb"}}, "__type__": "1"}, "cae2df13-1ccd-4524-bdf7-8f43fca04812": {"__data__": {"text": "GitHub Actions workflow  terraform.yml  under  .gitub/workflows  directory for \nrunning Terraform init/plan/apply, along with the workflows to deploy project code to \nits corresponding AWS resources.  \nBased on the  3\u20132\u20131 rule for DevOps self -service pipeline architecture , we can see that \nour three types of source code are  highlighted in red rectangles below: GitHub Actions \nworkflows, application source code, and Terraform code.  ", "doc_id": "cae2df13-1ccd-4524-bdf7-8f43fca04812", "embedding": null, "doc_hash": "8749bdc6bbe31726957816e2a7bb15919a73ceb661c9f658bd6d2ad08d0d56f6", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 439}, "relationships": {"1": "640347d5-3738-46c8-b4a4-f5df9d48f810"}}, "__type__": "1"}, "f81e0bd3-0bd8-4c76-8f9a-942b5f3eb40f": {"__data__": {"text": " \nimage by author  \n", "doc_id": "f81e0bd3-0bd8-4c76-8f9a-942b5f3eb40f", "embedding": null, "doc_hash": "4d37c7875ec4af5b935a4833a7fb511b3c2b385c06dd6d75d8c8ad451d883c02", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 20}, "relationships": {"1": "5c39a593-b837-494b-8116-4390d85cf281"}}, "__type__": "1"}, "2b2454ba-2a84-4490-b835-a76e89faece6": {"__data__": {"text": "How to call reusable modules from project -specific Terraform code  \nSince Terraform modules reside in  reusable -workflows -modules  repo, project -\nspecific Terraform code only carries project -specific logic, such as environment -specific \nconfigurations. We are not repeating the reusable module logic. We can call the reusable \nTerraform modules located in  reusable -workflows -modules  repo \nfrom main.tf  under the project root.  \nIt\u2019s best practice always to pin Terraform module source to a particular version, \nor main  in our sample below, referring to the latest version of the \nbranch  main  of reusable -workflows -modules  repo.  \nOur Terraform reusable modules reside in a subdirectory of  reusable -workflows -\nmodules  repo:  github.com/wenqiglantz/reusable -workflows -\nmodules/terraform/modules . To specify the Terraform module subdirectory, we \nneed to place a special double -slash syntax right after the repo name . Terraform \ninterprets the double -slash to indicate that the remaining path after that point is a \nsubdirectory within the repo.  \nTo pin Terraform module source to a particular branch, the  main  branch of  reusable -\nworkflows -modules  repo, we add  ?ref=main  at the end of the module name. Here\u2019s \na sample code snippet of how  springboot -infracost -demo  app\u2019s  main.tf  calls the \nreusable module  lambda : \nmodule \"lambda\"  { \n  source           = \"github.com/wenqiglantz/reusable -workflows -\nmodules//terraform/modules/lambda?ref=main\"  \n  s3_bucket_name   = var.s3_bucket_name  \n  s3_object_key     = var.s3_object_key  ", "doc_id": "2b2454ba-2a84-4490-b835-a76e89faece6", "embedding": null, "doc_hash": "c279d392f2c0cafb2bda579f28c306b37aaa439367366977e9cf8915efe9dd8a", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1573}, "relationships": {"1": "f1149b95-a761-4a10-88ca-3c521506e885"}}, "__type__": "1"}, "d20b36ef-fbf5-46a3-a1d5-57da77342573": {"__data__": {"text": "  lambda_functions  = var.lambda_functions  \n} \nGroup .tfvars files under the environment -related directories  \nNotice the screenshot below from an application repo, we have  terraform.tfvars  file \nlocated under the environment -related directories such as  dev, qc, \nand prod  under  .env . These are the files holding environment -specific values for the \nvariables.  \n \nRemote State Management  \n", "doc_id": "d20b36ef-fbf5-46a3-a1d5-57da77342573", "embedding": null, "doc_hash": "66badfd76d983b7f15c6c9d99e4423e11413a0c8479f521e3335a0684f6b5e25", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 401}, "relationships": {"1": "34444987-dd7b-43f2-bf76-fb289ffae1fa"}}, "__type__": "1"}, "aa428afe-0ee7-4757-8f5e-96eadcf191be": {"__data__": {"text": "There is a known  open issue  on the limitation of not being able to pass in variables \nin backend.tf  for remote state management in S3. As  backend.tf  is called \nduring  terraform init , and there is no way for terraform to parse variables \nin backend.tf  before it's initialized. Fortunately , there is a workaround. Here\u2019s three \nsteps to follow:  \n\u2022 We can keep the  backend.tf  file at the terraform root, as shown in the \nscreenshot above, but this file will hold no S3 -specific details. Here\u2019s a \ncode snippet of  backend.tf : \nterraform {  \n  backend \"s3\" { \n    //details in .env/{env}/backend.tfvars  \n  } \n} \n\u2022 We add a  backend.tfvar  file under the  .env  directory under its \nrespective environment folder. This file contains the S3 bucket name, key, \nregion, and the encrypt flag. See the following snippe t \nfor .env/dev/backend.tfvar : \nbucket         = \"terraform -remote-backend-dev\" \nkey            = \"demo/state.tfstate\"  \nregion         = \"us-east-1\" \nencrypt        = \"true\" \n\u2022 We then run  terraform init  by passing in this  backend.tfvar . \nHere\u2019s the snippet to run that locally:  ", "doc_id": "aa428afe-0ee7-4757-8f5e-96eadcf191be", "embedding": null, "doc_hash": "2c317e51841f2cac230e1f4fb2712e13eec029607d379fccf725b258c43df461", "extra_info": {"page_label": "11"}, "node_info": {"start": 0, "end": 1111}, "relationships": {"1": "3ba133f4-e84f-4b65-97c5-2debb3b0df0c"}}, "__type__": "1"}, "7c547ec5-a163-4f1e-91ef-f37ae1254778": {"__data__": {"text": "terraform init -backend-config='./.env/dev/backend.tfvars'  \nWhen running the GitHub Actions workflow, we get the following \nfrom  terraform.yml : \nterraform init -backend-config='./.env/${{ \ngithub.event.inputs.environme nt || 'dev' }}/backend.tfvars'  -\nupgrade= true -no-color -input=false \n.gitignore  \nBe sure to revise your  .gitignore  file at your project root to instruct GitHub to ignore \ncertain terraform files/directories. Here\u2019s a sample of the Terraform -related \nfiles/directories to be ignored in  .gitignore : \n#######################################  \n# Terraform files/directory to ignore #  \n#######################################  \n# Local .terraform directories  \n**/.terraform/*  \n \n# .tfstate files  \n*.tfstate  \n*.tfstate.*  \n \n# Crash log files  \ncrash.log  \ncrash.*. log \n \n# Ignore override files as they are usually used to override \nresources locally and so  \n# are not checked in  \noverride.tf  \noverride.tf.json  ", "doc_id": "7c547ec5-a163-4f1e-91ef-f37ae1254778", "embedding": null, "doc_hash": "e8c673550fb1f1eb8ab786965d9709b2c622cf7e6b6e6877bb18815dc58e4eab", "extra_info": {"page_label": "12"}, "node_info": {"start": 0, "end": 947}, "relationships": {"1": "e9841f25-8514-4d6d-805e-81e6731f0ec9"}}, "__type__": "1"}, "d3b29716-0c2e-4b00-8a22-5fc1673af04b": {"__data__": {"text": "*_override.tf  \n*_override.tf.json  \n \n# Include override files you do wish to add to version control \nusing negated pattern  \n# !example_override.tf  \n \n# Include tfplan files to ignore the plan output of command: \nterraform plan -out=tfplan  \n# example: *tfplan*  \n \n# Ignore CLI configuration files  \n.terraformrc \nterraform.rc  \n \n# Lock \n.terraform.lock.hcl  \n \n# Plan files  \n*.tfplan  \nGitHub Actions Workflow for Terraform  \nGitHub Actions workflow is used to run  terraform init , plan , apply , \nand destroy  for your project. First, let\u2019s get to the housekeeping items to en sure that \nGitHub secrets are properly configured.  \nSecrets configuration  \nThe only GitHub environment secrets needed to run the terraform workflow \nare TERRAFORM_ROLE_TO_ASSUME  and AWS_REGION . Configure them accordingly per \nyour AWS account setup.  \nTerraform r eusable workflow  ", "doc_id": "d3b29716-0c2e-4b00-8a22-5fc1673af04b", "embedding": null, "doc_hash": "79a319149b627288314a2b0c97cf3d67217a5b4f91ae77c697b19f2f69431b53", "extra_info": {"page_label": "13"}, "node_info": {"start": 0, "end": 872}, "relationships": {"1": "5d140a99-34a8-48d2-9a3b-2d6aa6d2f5c2"}}, "__type__": "1"}, "a9b83356-53a7-45ec-af57-cf714286ce2a": {"__data__": {"text": "A reusable GitHub Actions workflow for Terraform deployment has been extracted \ninto reusable -workflows -modules  repo , details of this reusable \nworkflow  terraform.yml  are as follows:  \nA few important highlights:  \n\u2022 Notice line 69 above,  git config --global \nurl.\"https://oauth2:${{ secrets.NPM_TOKEN \n}}@github.com\".insteadOf  https://github.com . This is \nimportant if your reusable modules reside in a private repo. We are \npassing a  NPM_TOKEN  that has access to the private repo as the client app \ndoesn't pass such credentials when calling Terraform reusable module \n(credit:  Unable to init with private repo modules \u00b7 Issue #33 \u00b7 \nhashicorp/setup -terraform  ). This line is critical. Without this line, the \nworkflow will fail at  terraform init  step due to not being able to \nacce ss the  reusable -workflows -modules  private repo without \npassing in a valid token.  \n\u2022 Also, notice we are passing in  terraform.tfvars  with  -var-file  to \nthe Terraform commands. Depending on the environment passed in from \nthe workflow_dispatch  manual trigger, Ter raform workflow checks in \nthe environment folder under  .env , runs for that chosen environment \nwith the respective  .tfvars  file passed in.  \n\u2022 terraform apply  step only executes on  apply-branch  which is \npassed in from the calling workflow, it defaults to the default branch in ", "doc_id": "a9b83356-53a7-45ec-af57-cf714286ce2a", "embedding": null, "doc_hash": "a5f9748a7ea55f1f597e8bd08e3fe6f417518d4e1923fde3575abb95ce8a2c27", "extra_info": {"page_label": "14"}, "node_info": {"start": 0, "end": 1360}, "relationships": {"1": "91a6c7f2-45fe-418d-86cc-f274852408c5"}}, "__type__": "1"}, "af6795e9-7220-4df6-8b9d-4a3b30e635b7": {"__data__": {"text": "your repo, such as  main , depending on the branching strategy for your \nrepo.  \n\u2022 To run  terraform destroy , create a feature branch,  destroy , and \ntrigger this workflow from that b ranch to destroy.  \nHow To Call Terraform Reusable Workflow  \nWhen deploying Terraform files, your app\u2019s workflow should be calling the above \nTerraform reusable workflow. Here\u2019s a sample  terraform.yml  from an app that calls \nTerraform\u2019s reusable workflow:  \nWith this, you have a fully functional infrastructure pipeline up and running to provision \nyour cloud resources for your application.  \nSummary  \nWe explored DevOps self -service centric Terraform project structure in this article. We \nlooked into what Terraform reus able modules are, their benefits, and how they are \nstructured in the GitHub repo.  \nWe then moved on to examine the code structure of the three types of source code in an \napplication repo and how to trigger a call from the application repo\u2019s Terraform code t o \nthe reusable module in the centralized repo.  \nFinally, we dived deep into the details of Terraform GitHub Actions workflow, both the \nreusable workflow in the centralized repo and the calling workflow from the application \nrepo. I hope you find this story h elpful on your path toward DevOps self -service.  ", "doc_id": "af6795e9-7220-4df6-8b9d-4a3b30e635b7", "embedding": null, "doc_hash": "bb545bc76bd14510885abb9712c0004ed7fa9b50e09b7053a039db5857439fe2", "extra_info": {"page_label": "15"}, "node_info": {"start": 0, "end": 1289}, "relationships": {"1": "e9483f45-7cae-49f1-b462-3a24c00c7f0c"}}, "__type__": "1"}, "c1214439-5a89-4606-967a-0e0dd8f81f3a": {"__data__": {"text": "The sample code for this story can be found in the following GitHub repos:  \n\u2022 reusable -workflows -modules  \n\u2022 springboot -infracost -demo  \nI welcome you to check out the rest of the four parts in my five -part \u201cThe Path to DevOps \nSelf-Service\u201d series:  \n \nDevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \nA high -level architectural overview of the self -service pipeline  \nbetterprogramming.pub  \n \n \nDevOps Self -Service -Centric GitHub Actions\u2019 Workflow Orchestration  \nHow to orchestrate GitHub Actions\u2019 workflows that are driven by image immutability  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Security and Guardrails  \nA list of hand -picked actions for security scans and guardrails for your pipelines, \ninfrastructure, source code, base\u2026  \nbetter programming.pub  \n \n \nDevOps Self -Service Centric Pipeline Integration  \nSecrets management as the glue of pipeline integration  \nbetterprogramming.pub  \n \nHappy coding!  \nReferences  \n \nThe top programming languages  ", "doc_id": "c1214439-5a89-4606-967a-0e0dd8f81f3a", "embedding": null, "doc_hash": "0bf150175fb4e93529877a2cd3b41148b007213e6969eef7e226b7553237ea3b", "extra_info": {"page_label": "16"}, "node_info": {"start": 0, "end": 1019}, "relationships": {"1": "a586736c-bddb-4322-b257-0cc45713bbb5"}}, "__type__": "1"}, "40647e1a-cfdd-4caf-bf5a-4800e91c32ea": {"__data__": {"text": "Languages After nearly 30 years of Java, you might expect the language to be showing \nsome signs of wear and tear, but\u2026  \noctoverse.github.c om \n \n \nTerraform Modules: Create Reusable Infrastructure As Code | Build5Nines  \nTerraform, being an Infrastructure as Code (IaC) tool, enables you to  write declarative \ncode that is then used to\u2026  \nbuild5nines.com  \n \n \nUnable to init with private repo modules \u00b7 Issue #33 \u00b7 hashicorp/setup -terraform  \nI have a terraform project that uses private repo modules. All of the repositories are \nunder my organization's control\u2026  \ngithub.com  \n ", "doc_id": "40647e1a-cfdd-4caf-bf5a-4800e91c32ea", "embedding": null, "doc_hash": "2e2a2a9dd948df4b68d5e0e6cc2e045cb78f3f960bdc3af3b1d5312f7eea3aa9", "extra_info": {"page_label": "17"}, "node_info": {"start": 0, "end": 585}, "relationships": {"1": "ddb354c3-0212-4263-bbc2-05125ec89a6f"}}, "__type__": "1"}, "6627abff-fbdf-437a-a9d1-bb383554a063": {"__data__": {"text": "DevOps Self -Service Pipeline Architecture and Its 3 \u20132\u20131 Rule  \nA high -level architectural overview of the self -service pipeline  \n \nDevOps Self -Service Calls for Drastic Mindset Change  \nWhether you call it DevOps self -service, democratizing DevOps, or Platform Engineering, \nthe goal is the same \u2014 to empower developers with more access, control, and ownership \nover the pipelines to boost productivity.  \nLet\u2019s call it \u201cDevOps self -service\u201d in t his article to be consistent in our terms.  \n", "doc_id": "6627abff-fbdf-437a-a9d1-bb383554a063", "embedding": null, "doc_hash": "fd4501ca5bf18b4ad1921b2f65ff187edcec7aa37733a942b9b10a167464eee5", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 500}, "relationships": {"1": "01c0c0d1-b8be-4b29-b3a3-4bc609f73819"}}, "__type__": "1"}, "a5435533-d92c-43d8-a5aa-0a5fed54c098": {"__data__": {"text": "Why drastic mindset change? Let\u2019s start with exploring our self -service pipeline \narchitecture from a high level.  \nSelf-Service Pipeline Architecture  \nThe diagram below depicts a generic self -service pipeline archite cture based on a 3 \u20132\u20131 \nrule (a term I coined while drawing the diagram): Three types of source code. Two types \nof pipelines. One pipeline integration glue. I mention the word \u201cgeneric\u201d mainly because \nthere are many variations of the pipeline architecture b ased on the types of workloads. \nThis generic pipeline design is more tailored for microservices architecture, not for \nserverless workloads. Serverless pipeline architecture should be even simpler.  \n \ndiagram by author  \nLet\u2019s dive in to see what exactly this 3 \u20132\u20131 rule entails.  \nThree Types of Source Code  \nThe following three types of source code will reside in the same G itHub repository for \nyour microservice.  \n", "doc_id": "a5435533-d92c-43d8-a5aa-0a5fed54c098", "embedding": null, "doc_hash": "a079462cb1a0cebb7d05f9bfe45f0f8bcc666f4217f36303f41b53eb0426f1e8", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 906}, "relationships": {"1": "44071d89-212c-4714-953e-950cae500e7d"}}, "__type__": "1"}, "a1d004b8-c5ca-4f1d-ba37-dbb71a4fab41": {"__data__": {"text": "\u2022 Terraform code: yes, we have Terraform code residing in application \nrepositories. This, perhaps, is the most challenging for some to accept as \nwe have been used to having Terraform code centralized in a particular \nDevOps repo, no developers allowed. Now with DevOps self -service, we \nare relinquishing the Terraform code to developers, partially, into the \napplication repos. Why partially? because we are keeping the Terraform \nreusable modules in a centralized repo still. More on Terraform reusable \nmodules and Terraform project structure in my story titled  DevOps Self -\nService Centric Terraform Project Structure . \n\u2022 Project source code: this is our good old source code for our app, be it \nJava, Node.js, Python, or other programming languages.  \n\u2022 GitHub Actions workflow code: for those who are familiar with GitHub \nActions, this is no surprise, as the actions workflow yml f iles have to reside \nin the  .github/workflows  directory at the root of our app.  \nTwo Types of Pipelines  \n\u2022 Infrastructure pipeline: IaC with Terraform. Picking Terraform here is \nmainly because of its cloud -agnostic and open source nature. A GitHub \nActions Terra form workflow can kick off the infrastructure pipeline to \nprovision cloud resources such as services in AWS.  \n\u2022 Application pipelines: our application CI/CD pipelines, kicked off by \nGitHub Actions workflows. These are the pipelines to build, test, scan, and \ndeploy our apps into our cloud providers.  \nOne Pipeline Integration Glue  ", "doc_id": "a1d004b8-c5ca-4f1d-ba37-dbb71a4fab41", "embedding": null, "doc_hash": "05ed150ae150899149fae9aa6f493fb6eebda4d03e24dda6e31bd6eea3455e05", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 1501}, "relationships": {"1": "90c9fb37-6f25-4b81-bec7-213f75767395"}}, "__type__": "1"}, "5923cbea-6104-4217-83e4-8939801076c3": {"__data__": {"text": "\u2022 How do we tie infrastructure pipelines with application pipelines to make \nthem work together seamlessly? We need a glue to integrate these two \ntypes of pipelines. And this glue is GitHu b secrets creation automation. \nUpon successful infrastructure provisioning, we can use Terraform to \nautomate GitHub secrets creation by calling the GitHub provider. Notice \nthe double -ended arrows for the infrastructure pipeline in the diagram \nabove, as the  Terraform outputs for the secrets get inserted into GitHub \nautomatically. This eliminates manual secrets creation and enables \napplication pipelines to kick off CI/CD for the specified GitHub \nenvironment with the secrets associated with that particular Git Hub \nenvironment provided by Terraform through the infrastructure pipeline. \nThis accomplishes the end -to-end, state -of-the-art integration of these two \ntypes of pipelines.  \nHigh -Level Design of DevOps Pipelines  \nWe will dive deeper into the project structures  for Terraform, its reusable modules, and \nthe GitHub Actions workflow orchestration in future stories. For now, let\u2019s take a high -\nlevel overview of what the two types of pipelines look like, what they do, and what \ndetailed steps are involved.  \nInfrastructur e Pipeline  \nGiven its cloud -agnostic and open source nature, Terraform is the tool of our choice to \nbuild our infrastructure as code (IaC).  \nTerraform GitHub Actions workflow  \nHere is a high -level overview of what our Terraform GitHub Actions workflow looks l ike: ", "doc_id": "5923cbea-6104-4217-83e4-8939801076c3", "embedding": null, "doc_hash": "0ed3a154e1944e6d737d71a38ce412fb39ec920775aeb228c407bac3c4c37754", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 1513}, "relationships": {"1": "0323df1d-53c9-4b1f-af91-39b8174dcf4e"}}, "__type__": "1"}, "6899b2df-0359-491d-b727-6b974db86bfd": {"__data__": {"text": " \ndiagram by author  \nNote : The diagram does not depict alternative flows, such as for  terraform destroy . \nYou can always add alternative flows per your pipeline requirements.  \nApplication Pipelines  \nOur application pipelines are developed using GitHub Actions. Below is a high -level \noverview of the two typical pipelines (CI and CD for microservices). These are mere \nexamples. Your workflows could contain different steps depending on the nature of your \napplications.  \nMicroservice CI GitHub Actions workflow  \n", "doc_id": "6899b2df-0359-491d-b727-6b974db86bfd", "embedding": null, "doc_hash": "ead9b0ccbac26fdaf6d44654b15d99663b2fbbd64f64fe552d6e0204890044b9", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 522}, "relationships": {"1": "eb6f6260-d5a8-400c-9f7b-41e2a083b1a3"}}, "__type__": "1"}, "2f9403db-f6eb-414f-a122-61a99a958999": {"__data__": {"text": " \ndiagram by author  \nMicroservice CD GitHub  Actions workflow  \n \ndiagram by author  \nInfrastructure/Application Pipelines Integrated  \nHere\u2019s some key points to highlight:  \n\u2022 Terraform code and GitHub Actions workflow co de reside in the \napplication\u2019s GitHub repository.  \n", "doc_id": "2f9403db-f6eb-414f-a122-61a99a958999", "embedding": null, "doc_hash": "7645ed8a1799d653bfccd8071d4b334cea2b5982902e28bd491c261aa4aa99e8", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 277}, "relationships": {"1": "2b3b1e49-618a-4885-992d-ae06c1fb7a4e"}}, "__type__": "1"}, "62641cda-9abd-4725-b6e3-af5a9cd90e2b": {"__data__": {"text": "\u2022 App\u2019s Terraform code calls Terraform reusable modules, which reside in a \ncentralized GitHub repository.  \n\u2022 The infrastructure pipeline can be kicked off by either a manual trigger or \nPR creation/merge of Terra form code using GitHub Actions Terraform \nworkflow to provision cloud resources.  \n\u2022 Upon successful infrastructure provisioning, Terraform automates GitHub \nsecrets creation by calling the GitHub provider. Notice the double -ended \narrows for the infrastructure p ipeline in the diagram above as the \nTerraform outputs for the secrets get inserted into GitHub automatically. \nThis eliminates manual secrets creation.  \n\u2022 Upon PR creation/merge of application code, or manual trigger, \napplication pipelines are triggered by Git Hub Actions workflows for CI \nand CD to build, test, scan, and deploy our app into the cloud.  \nSummary  \nDevOps self -service has gained traction in recent years mainly due to the growing trend \nof cloud -native architecture. This article focused on the overall s elf-service pipeline \ndesign and the main ingredients in DevOps self -service. The 3 \u20132\u20131 rule outlines the \noverall architecture of a self -service DevOps practice. I hope you find this story helpful.  \nI welcome you to check out the rest of the four parts in my five -part \u201cThe Path to DevOps \nSelf-Service\u201d series:  \n \nDevOps Self -Serv ice Centric Terraform Project Structure  \nHow to structure Terraform code and its reusable modules  \nbetterprogramming.pub  ", "doc_id": "62641cda-9abd-4725-b6e3-af5a9cd90e2b", "embedding": null, "doc_hash": "d07d961758b90f92eb4448d0219ece8a9fccd548e25d3f359eb7ba6360d739a4", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 1473}, "relationships": {"1": "23643c82-3c82-4846-85d3-dbbb6f504561"}}, "__type__": "1"}, "859206aa-6453-4fce-af88-7a71b327324e": {"__data__": {"text": " \n \nDevOps Self -Service Centric GitHub Actions\u2019 Workflow Orchestration  \nHow to orchestrate GitHub Actions\u2019 workflows that a re driven by image immutability  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Security and Guardrails  \nA list of hand -picked actions for security scans and guardrails for your pipelines, \ninfrastructure, source code, base\u2026  \nbetterprogramming.pub  \n \n \nDevOps Self -Service Centric Pipeline Integration  \nSecrets management as the glue of pipeline integration  \nbetterprogramming.pub  \n \nHappy coding!  ", "doc_id": "859206aa-6453-4fce-af88-7a71b327324e", "embedding": null, "doc_hash": "ea111962282b0c5c3b400e6157304fdb0d12315b8db3d7b01c8edeaf08059a90", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 553}, "relationships": {"1": "b9793ff4-59e4-4749-af15-12c52ccd9f84"}}, "__type__": "1"}, "14af71e5-d868-4def-beae-ac1d87f4453a": {"__data__": {"text": "Troubleshooting Tips for GitHub Actions Workflows  \nA compilation of GitHub Actions workflows errors and solutions from my own work \nexperience  \n \nPhoto by author  \nWhile working with GitHub Actions workflows building and deploying microservices into \nAWS, I h ave run into some errors/exceptions and dived deep into finding their solutions. \nI am listing a collection of such error scenarios and their solutions, hoping to be of some \nhelp to those who are working with GitHub Actions.  \n", "doc_id": "14af71e5-d868-4def-beae-ac1d87f4453a", "embedding": null, "doc_hash": "c5e092377621eed0f255342cae514ea24877d3dbb0da758b886e260edd545596", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 490}, "relationships": {"1": "c9c564fe-88e9-4d48-954d-e720d7c8f7b2"}}, "__type__": "1"}, "8d7047da-27e4-4e37-95e3-14b9ec833b16": {"__data__": {"text": "The detailed CI/CD workflows ref erenced in the troubleshooting details below are \ndocumented in my story \u201c A Deep Dive into GitHub Actions\u2019 Reusable Workflows \u201d. \nError #1: CI workflow failed at \u201cScan ECR Image with Trivy vulnerability scanner\u201d \nstep \nIf you use  Trivy  to scan your docker image and if  your CI workflow failed at the ECR \nimage scan step with the following error (see screenshot below), which is caused by a \nvulnerability issue in the docker base image. In this case, base \nimage  amazoncorretto:17.0.2 -alpine3.15  was used for Spring Boot \nmicro services (no new image with the fix has been published as of this writing), you will \nneed to provide the workaround to update the packages in your base image in \nyour  Dockerfile . \nSpecifically, add line  RUN apk update && apk upgrade -U -a under \nthe FROM  line in your  Dockerfile . With this one -line fix, your CI should be able to pass \nthat ECR image scan step. By the way, I highly recommend Trivy for image scan, it not \nonly scans your app\u2019s dependencies to check vulnerabilities, it also scans your base \nimage. Ad d Trivy scan to your CI workflow if you haven\u2019t already.  \n \nError #2:  release workflow failed with \u201c500 Internal Server Error\u201d  \n", "doc_id": "8d7047da-27e4-4e37-95e3-14b9ec833b16", "embedding": null, "doc_hash": "763e5810f5bf37d9999d5dcdb35fc0bd10048e47bff8c616f3a1c82499f7449a", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 1227}, "relationships": {"1": "2938da21-4392-4b11-abc5-7791595fbb18"}}, "__type__": "1"}, "3c064289-01af-4057-9acd-72764b5a19fa": {"__data__": {"text": "During the course of testing the maven releas e workflow, I run into \u201c500 Internal Server \nError\u201d and pointing to GitHub Packages not behaving as expected. I contacted GitHub \ntech support regarding this error, and here is their response:  \n\u201cIt looks like this was a transient error, which possibly happene d during a time of high \nload \u201d. They recommended the following workaround to allow retry when such an error \noccurs. If by any chance you still run into this error even after 3 retries, the best way to \nclean up the release process is to manually bump up the main\u2019s pom version to the next \ndevelopment snapshot version, and re -release the new version.  \nenv: \n  MAVEN_OPTS: -Dhttp.keepAlive= false -Dmaven.wagon.http.pool= false \n-Dmaven.wagon.http.retryHandler. class=standard -\nDmaven.wagon.http.retryHandler.count= 3 \nError #3: \u201cCouldn\u2019t retrieve verification key from your identity provider, please \nreference AssumeRoleWithWebIdentity documentation for requirements\u201d  \nIf you run into the above error at step \u201cConfigure AWS c redentials\u201d, it indicates a \nmisconfiguration for OIDC. Follow the four steps below to properly configure OIDC in \nAWS.  \nStep 1: Add the Identity Provider (if it doesn\u2019t exist already)  \n1. Open the IAM console.  \n2. In the navigation pane, choose \u201cIdentity providers\u201d,  and then choose \u201cAdd \nprovider\u201d.  \n3. For \u201cConfigure provider\u201d, choose \u201cOpenID Connect\u201d.  ", "doc_id": "3c064289-01af-4057-9acd-72764b5a19fa", "embedding": null, "doc_hash": "f781582f5aa49ce2eefc25a08a261258a6aae142bba9179d92fc395ee6dc93dc", "extra_info": {"page_label": "3"}, "node_info": {"start": 0, "end": 1403}, "relationships": {"1": "9823604f-a141-45bc-b693-724630fc08e5"}}, "__type__": "1"}, "137533b9-10eb-47ae-9cb2-06a2705d8958": {"__data__": {"text": "4. For \u201cProvider URL\u201d, \ntype  https://token.actions.githubusercontent.com  \n5. For \u201cAudience\u201d, type  sts.amazonaws.com  since we are using the  official \naction . \n6. Choose \u201cAdd provider\u201d.  \nStep 2: Add Role and Trus t Policy  \nAdd a new role and assign policies as needed for your new application. The policies in \nthis step could vary depending on the specific application you are planning to deploy. If \nthere is an existing role you would like to use, be sure it\u2019s configur ed correctly by \nverifying the following steps.  \nOnce the role is added, ensure its trust policy is defined like the \nfollowing,  Federated  line should specify the  ARN for the identity provider we just \ncreated above (sample snippet below for reference only, en sure you change the  ARN for \nthe identity provider according to your account on line 7). The  aud section (line 12) \nshould always have value  sts.amazonaws.com , as defined in the Identity Provider \nsection above.  \nStep 3: Add Inline Policy for ECR Access  \nFor microservices, it\u2019s a common step to build and push the docker image to ECR. The \nGitHub action we use,  aws-actions/amazon -ecr-login@v1 , to log into ECR \nrequires the push/pull permissions to ECR private repo. The built -in policies for ECR \ndidn\u2019t work fo r push/pull of images from/to private repo, unfortunately, so I had to ", "doc_id": "137533b9-10eb-47ae-9cb2-06a2705d8958", "embedding": null, "doc_hash": "28ac4acbcac2e25affecc443a3033e3aa99a903ce034e05610736efb8b764e91", "extra_info": {"page_label": "4"}, "node_info": {"start": 0, "end": 1340}, "relationships": {"1": "631941fd-6d25-4ec5-9372-0edbccc99634"}}, "__type__": "1"}, "f10fa093-172c-4bd5-9c37-23e933cf7d8a": {"__data__": {"text": "create an inline policy for ECR access. Add this inline policy to our role in addition to the \nexisting policies we already selected for that role:  \nStep 4: GitHub Actions Workflow Config uration  \nCreate a new GitHub Environment secret, with key  ROLE_TO_ASSUME , and value as that \nrole's  ARN. \nBefore the jobs are defined, we need to specify the permission in our GitHub Actions \nworkflow, need to add in particular,  id-token: write  permission in t he caller \nworkflow, which allows the JWT to be requested from GitHub's OIDC provider. We won't \nbe able to request the OIDC JWT token if the  permissions  setting for  id-token  is set \nto read  or none . \nError #4: \u201cNoCredentialProviders: no valid providers in cha in\u201d \nIf you happen to run into this error in your workflow execution, it usually indicates \nGitHub Actions cannot find the secrets defined. Check to see if you \nspecified  environment  in your workflow. If you are working on a brand new workflow \nwhich interacts  with AWS resources, be sure to add this line (see below) above the steps \ndefined in your workflow job.  \nenvironment:  ${{ inputs.env || 'dev' }} \nError #5: missing manual trigger even when you have workflow_dispatch trigger in \nyour workflow  ", "doc_id": "f10fa093-172c-4bd5-9c37-23e933cf7d8a", "embedding": null, "doc_hash": "d7719f5191b1db72c480f6f5ff26dbea3ce6f705384a4de64f9970fb06c49ae4", "extra_info": {"page_label": "5"}, "node_info": {"start": 0, "end": 1232}, "relationships": {"1": "eda414b3-c1f2-4eea-9328-5e8b9bf277eb"}}, "__type__": "1"}, "a9700d84-5150-4f28-bc85-4626d0a8f8eb": {"__data__": {"text": "If you have  workflow_dispatch  trigger defined in your workflow, but for some reason \nyou don\u2019t see the \u201cRun workflow\u201d button for your workflow under Actions tab i n your \nrepository, check to see if the branch you are in is the default branch of your repository. \nYou can merge your feature branch into your default branch, revise the trigger to point to \nyour feature branch, once code is merged, you will see the latest code and workflow file \nchanges reflected. You should now see the \u201cRun workflow\u201d button under the Actions tab, \nsee screenshot below.  \n \nError #6: GitHub PR page displays \u201cThis branch was successfully deployed\u201d even \nwhen you run a CI workflow  \nProvided you have the PR trigger in your workflow, when a new PR is raised, it \nautomatically triggers the CI workflow. No actual deployment is done to your AWS \nenvironment. You wonder why on the PR page GitHub displays this line \u201cThis branch \nwas successful ly deployed\u201c (see screenshot below). I contacted GitHub tech support, and \nhere is their response:  \n\u201cThis is happening because the workflow has a job that is referencing \nthe dev environment. When you reference an environment in a workflow job, GitHub \nimplici tly creates a deployment to that environment. Deployment in this case refers to \nthe deployments concept  in GitHub rather than to the external service provider.  \n", "doc_id": "a9700d84-5150-4f28-bc85-4626d0a8f8eb", "embedding": null, "doc_hash": "0b94b7a3a602657d73ffd3730fbe53cdcce51ece285ac1713d0743810700ccd5", "extra_info": {"page_label": "6"}, "node_info": {"start": 0, "end": 1357}, "relationships": {"1": "dbe35e52-c484-450b-9e00-41860c60b07d"}}, "__type__": "1"}, "c48bb421-bf6e-4f48-9a7c-07a4c2710907": {"__data__": {"text": "At the moment, there is no way to change or remove that message from the pull request \ntimeline if the job in the workflow is referencing an environment, sorry.  \nI agree that the message does seem confusing and we\u2019ve received similar feedback from \nother users about this. I have added this ticket to the discussion. I am not able to give \nyou a timeline for when changes to it will be made but this will be documented on \nour Changelog .\u201d \nIn our sample CI workflow, we need to reference the secrets defined in  dev GitHub \nenvironment to perform actions such as configure AWS credentials and push image to \nECR. With CI workflow referencing the  dev environment, it is the very reason why \nGitHub displays that message. Nothing we can do on our end. For now, just be aware of  \nthis message, and wait for GitHub to come up with a proper fix.  \n \nError #7: \u201cWorkflow does not exist or does not  have a workflow_dispatch trigger in \nthis tag\u201d  \nThis error happens when you try to deploy a released tag to any environment through \nmanual trigger by picking the specific tag. The reason for this error is that your workflow \nfile must have changed since your tag was created by maven release. This happens  when \n", "doc_id": "c48bb421-bf6e-4f48-9a7c-07a4c2710907", "embedding": null, "doc_hash": "b3a31c073482b4e8bb2c32164fc8c3874036582e8c718166fd9f0ba5383b5741", "extra_info": {"page_label": "7"}, "node_info": {"start": 0, "end": 1212}, "relationships": {"1": "6a265fd7-4c71-4257-aca0-4466706f024c"}}, "__type__": "1"}, "6f27a8db-f5dd-472c-a086-fd3c94bf9826": {"__data__": {"text": "you tweak/refine your workflows in the beginning phase of your adoption of GitHub \nActions. So if your workflow has changed since your last maven release, the best way to \nfix it is to just release a new version and deploy the new tag. That works!  \nError #8: Workflow failed at step \u201cBuild, tag, and push image to AWS ECR\u201d  \nIf you see an error in your GitHub Actions log under the step \u201cBuild, tag, and push image \nto AWS ECR\u201d, complaining about retrying multiple times trying to push image to ECR, \neventually r eturning exit code 1. It\u2019s most likely because your app either doesn\u2019t have an \nECR repository configured in the ECR registry, or your IAM Role for your app doesn\u2019t \nhave the proper permission configured in your ECR repository. Double -check both!  \nError #9: \u201c Input required and not supplied: aws -region\u201d  \nThis error occurs in \u201cConfigure AWS Credentials\u201d step. Even though you have your IAM \nRole and AWS_REGION properly added in GitHub secrets, you still run into this error, \nwhy? A few reasons:  \n1). Ensure your OIDC permission is properly set in your GitHub Actions workflow. Be \nsure to check you have the following permission defined properly before calling the \nreusable workflow containing \"Configure AWS Credentials\" or any other AWS actions.  \npermissions: \n  id-token: write # need this for OIDC   \n  contents:  read \n2). Ensure you have \u201cConfigure AWS Credentials\u201d step defined before any step that \nmanipulates environment variables. It appears to be a potential bug in AWS action ", "doc_id": "6f27a8db-f5dd-472c-a086-fd3c94bf9826", "embedding": null, "doc_hash": "12029ec7c2739a049ab39fae722f2e1b9879ebd3186a523bd1935131cfd317a4", "extra_info": {"page_label": "8"}, "node_info": {"start": 0, "end": 1514}, "relationships": {"1": "4ad6f52f-ff2a-4ae3-af91-7662b4322833"}}, "__type__": "1"}, "34658486-80ee-4f4d-ad0a-89b5783f3246": {"__data__": {"text": "\u201cConfigure AWS Credentials \u201d, whenever a github environment variable is defined and \npassed into $GITHUB_ENV, \u201cConfigure AWS Credentials\u201d step somehow pulls that \nenvironment variable and passes it to its action instead of the IAM role and AWS region \nvalues from secrets. So suggest to  always put \u201cConfigure AWS Credentials\u201d step before \nany step that deals with  $GITHUB_ENV . \nError #10:  \u201cno such file or directory\u201d when deploying artifacts  \nFor many of the microservices deploying images to ECS, reusable workflows have nailed \ndown the details  for deployment already, but for microservices which deploy artifacts \nother than docker image, such as deploying jar file to a Lambda function, this error \u201cno \nsuch file or directory\u201d may occur when the path to the artifact is not defined correctly, \nespecia lly in a monorepo scenario, or a nested project structure inside an existing legacy \nrepository. Be sure to specify the full file path to the artifact whenever the artifact path is \nrequired.  \nError #11: release workflow fails with artifact already exists err or \nSnapshot version can be released multiple times, but the release version can only be \nreleased once. If a developer tries to release the same version after that version has \nalready been released (the only possible reason for this could be the developer f orgot to \nmerge the latest code from the  release  branch into the  main  after the  release ), and \nthe release workflow will throw artifact \u201calready exists\u201d error. The only way to avoid such \nerrors is to ensure the release branch is merged back into the  main  once a version has \nbeen successfully released to GitHub Packages, which bumps up the version in  main  to \nthe next snapshot.  ", "doc_id": "34658486-80ee-4f4d-ad0a-89b5783f3246", "embedding": null, "doc_hash": "bcca875fe233205010bd954808ee194c153d45450a51f3b7f7d4f0ce842b3df0", "extra_info": {"page_label": "9"}, "node_info": {"start": 0, "end": 1725}, "relationships": {"1": "6dc1a8e3-e993-4ed0-934a-695709ec017f"}}, "__type__": "1"}, "47214ed0-9449-489f-9ab2-865eaf228313": {"__data__": {"text": "Error #12:  An error occurred (ClientException) when calling the \nDescribeTaskDefinition operation: Unable to describe task definition  \nIf by any chance your workflow fails at  describe -task-definition  step, with the \nerror seen in the screenshot below, you need to check two things:  \n1. Ensure there is no typo in your secret configuration \nfor ECS_TASK_DEFINITION . \n2. If you run this workflow in an e nvironment/account which is located in a \ndifferent region than the default  AWS_REGION  defined at your repo\u2019s \nsecret, you need to define  AWS_REGION  and AWS_DEFAULT_REGION  in \nyour environment secrets to overwrite the values for those secrets at the \nrepositor y or org level.  \n \nError #13:  Error \u201cCredentials could not be loaded, please check your action inputs: \nCould not load credentials from any providers\u201d  \nIf your workflow fails at the  configure -aws-credentials  step with the above error, \nsee screenshot below, the root cause is with permission for OIDC.  \n \n", "doc_id": "47214ed0-9449-489f-9ab2-865eaf228313", "embedding": null, "doc_hash": "fd7a0970b6aa668d62ce6a17db2bf10f6fd990169325a0af2afadcc0b3ec564b", "extra_info": {"page_label": "10"}, "node_info": {"start": 0, "end": 987}, "relationships": {"1": "8af5941f-5b46-41c0-abc6-8da065c06caa"}}, "__type__": "1"}, "33db5f2b-8dbb-47ae-a20d-5f3ecc869538": {"__data__": {"text": "You need to add permission for OIDC  id-token: write . If your workflow is cal ling a \nreusable workflow, permissions are set at the caller workflow, NOT in the reusable \nworkflow, so ensure your caller workflow has the following permissions properly set (line \n5\u20136) BEFORE you call the reusable workflow, sample snippet below:  \nError 14: \u201cnpm ERR! code E400 \u201d \nWhen you try to publish an npm package to GitHub Packages, if you run into this error, \nwith details such as the following:  \n\u201c253npm ERR! 400 Bad Request \u2014 \nPUT https://npm.pkg.github.com/@< repo-name>\u2014 failed to stream \npackage from json: unhandled input: Cannot publish over existing \nversion\u201d  \nIt indicates you cannot publish the same version package to GitHub Packages as that \nsame version already exists. So try bum ping up the version and retry.  \nError 15:  An error occurred trying to start process \u2018/usr/bin/bash\u2019 with working \ndirectory  \nThis error appears to be tricky, especially when all working -directory and paths are \ndefined properly for the workflow. The fix is act ually really simple. You need to always \nput the checkout code action ( actions/checkout ) right after the harden runner step \n(step-security/harden -runner ). Once the sequence is switched, this error \ndisappears!  ", "doc_id": "33db5f2b-8dbb-47ae-a20d-5f3ecc869538", "embedding": null, "doc_hash": "a98d8a7f51a45df67824ab2284f291ac98163626f7e892781ff84f64971b8407", "extra_info": {"page_label": "11"}, "node_info": {"start": 0, "end": 1268}, "relationships": {"1": "0d7c7cab-cf39-4e28-9eb8-f1e0eca6f87f"}}, "__type__": "1"}, "5221b705-81e3-4dc9-92d1-9b833d2702f5": {"__data__": {"text": " \nError 16:  \u201cConnection reset by peer\u201d  \nIf you run into intermittent error \u201c Connection reset by peer \u201d during \neither  terraform plan  or terraform apply  step, sample screenshot below, be \naware that this is a known issue with HashiCorp\u2019s  terraform -provider -aws, root \ncause appears to be with AWS API rate limits:  Intermittent connection reset by peer \nerror when Terraform apply \u00b7 Issue #23614 \u00b7 hashicorp/terraform -provider -aws \n(github.com) . \nAn enhancement to retry in such an error scenario has been submitted here,  Add retry \nhandling when a request's connection is reset by a peer \u00b7 Issue #10715 \u00b7 \nhashicorp/terraform -provider -aws (github.com) . \nAs of this writing, that enhancement is still in open status. We hope this enhancemen t \ngets implemented soon by HashiCorp team. Meanwhile, if you encounter a such error \nduring your workflow run, please retry your workflow, the error should usually go away.  \n", "doc_id": "5221b705-81e3-4dc9-92d1-9b833d2702f5", "embedding": null, "doc_hash": "1ecdee6f3b0ab1d7f31c39f2bd90743748b0a0a6d283cb10581a55eb4117929b", "extra_info": {"page_label": "12"}, "node_info": {"start": 0, "end": 932}, "relationships": {"1": "f3ccb2a3-1da8-4985-a1a0-66ed18fb4649"}}, "__type__": "1"}, "40a0a193-2045-4e30-a8ad-ef3f12e2e432": {"__data__": {"text": " \nError 17:  Version ### not found in the setup step  \nThis error was uncovered in the \u201cSet up Python\u201d step for one of our Python apps. See the \nscreenshot below. It appears to be odd because the previous runs for that same workflow \nhad no issue with setting up Python. The root cause of this particular issue wa s \nUbuntu/Python version compatibility.  \nIf your GitHub -hosted workflow runners run on  ubuntu-latest  version, which could \nmean varied Ubuntu version numbers depending on what the latest Ubuntu version is. \nFor example, the following workflow\u2019s Ubuntu version was 22.04, which does not offer a \npython version 3.8.8 for that action as indicated in the link in that screenshot below the \nerror message, while the workflow runs prior to that had Ubuntu version 20.04, which \ndoes offer a python version 3.8.8 for that par ticular action.  \n", "doc_id": "40a0a193-2045-4e30-a8ad-ef3f12e2e432", "embedding": null, "doc_hash": "0b4a11728b69bfc3773681cb39a2b8ed0dfd96f02834fc55cc4728095e5e5522", "extra_info": {"page_label": "13"}, "node_info": {"start": 0, "end": 856}, "relationships": {"1": "eab0ec86-7081-443e-8585-6d84b44ef160"}}, "__type__": "1"}, "ee685157-1739-4a8d-a18b-ddb4bb5bb124": {"__data__": {"text": "A classic example of version incompatibility. The fix is to change in the workflow file to \npoint to the compatible Ubuntu version from  runs-on: ubuntu -latest  to runs-\non: ubuntu -20.04 . It would require much more effort and testing from the \ndevelopment team to upgrade Python version of their app, which should still be an \noption for the team to consider in the longer term. The best practice is to revisit this \nversion manifest link in a period of time to see if the latest Ubuntu version does sup port \nyour particular Python version and upgrade the Ubuntu version accordingly. Or better \nyet, upgrade the Python version of your app when the resource and time are ready.  \n \nTo find out which version of Ubuntu your workflow runner runs on, you can expand \u201cSet \nup job\u201d step in your workflow run result page, expand \u201cOperating System\u201d to capture the \nactual Ubuntu version.  \n", "doc_id": "ee685157-1739-4a8d-a18b-ddb4bb5bb124", "embedding": null, "doc_hash": "1a0a8274283e37a1b5e65f362875a5cdc402799c20e699a6c0d6223cb084740f", "extra_info": {"page_label": "14"}, "node_info": {"start": 0, "end": 886}, "relationships": {"1": "dcbdf637-2f86-4213-a983-6484e97a8bef"}}, "__type__": "1"}, "5866dc58-9abb-4faf-ae4a-674d7ea2ec0a": {"__data__": {"text": " \nWe explored some of the errors I encountered during working with GitHub Actions \nworkflows. I hope this list helps save some troubleshooting time for those who work with \nGitHub Actions workflows.  \nHappy Coding!  \n \n", "doc_id": "5866dc58-9abb-4faf-ae4a-674d7ea2ec0a", "embedding": null, "doc_hash": "ba85732c739a3dfea6ce9ea0bd0a2ae1eec7165343aabb48e991a88d23163ac8", "extra_info": {"page_label": "15"}, "node_info": {"start": 0, "end": 219}, "relationships": {"1": "c89d44c0-5231-4a99-a127-84669253d9f5"}}, "__type__": "1"}}}